{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "643c7b1d",
   "metadata": {},
   "source": [
    "# Fine tuning the model to make a chat bot\n",
    "\n",
    "This is the big guacamole at the end of the rainbow. We'll be fine tuning one of the OpenAI models to be able to respond sort of like ChatGPT. I think there's an example of trying to do this on the foundation model in `openai.ipynb` without fine-tuning, and right now it _sucks_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6aec3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import openai # type:ignore\n",
    "import gpt # type:ignore\n",
    "import torch\n",
    "import urllib\n",
    "import ssl\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from typing import TypedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "from functools import partial\n",
    "import textwrap\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    if torch.cuda.is_available(): # type: ignore[attr-defined]\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available(): # type: ignore[attr-defined]\n",
    "        return torch.device(\"mps:0\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948a0d4",
   "metadata": {},
   "source": [
    "## Download the instruction training data\n",
    "\n",
    "This is 1,100 instruction-response pairs (actually some have a third field called input) that were made specifically for the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f063394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n",
      "Example:\n",
      "{'input': 'He go to the park every day.',\n",
      " 'instruction': 'Edit the following sentence for grammar.',\n",
      " 'output': 'He goes to the park every day.'}\n"
     ]
    }
   ],
   "source": [
    "class InstructionExample(TypedDict):\n",
    "    instruction: str  # A description of the task to be performed\n",
    "    input: str        # Optional parameter for the task\n",
    "    output: str       # The expected result of performing the task\n",
    "\n",
    "def download_and_load_file(file_path: str, url: str) -> list[InstructionExample]:\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response: # type:ignore\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n",
    "print(\"Example:\")\n",
    "pprint(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab7037",
   "metadata": {},
   "source": [
    "## Convert the examples to Stanford Alpaca format\n",
    "\n",
    "The [format](https://github.com/tatsu-lab/stanford_alpaca) looks like this:\n",
    "\n",
    "```\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "```\n",
    "\n",
    "Or, if there's no input:\n",
    "\n",
    "```\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07052c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry: InstructionExample, include_response:bool=True) -> str:\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry[\"input\"]}\" if entry[\"input\"] else \"\"\n",
    "    response_text = f\"\\n\\n### Response:\\n{entry[\"output\"]}\" if include_response else \"\"\n",
    "\n",
    "    return instruction_text + input_text + response_text\n",
    "\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94965cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data: list[InstructionExample], tokenizer: tiktoken.Encoding):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            full_text = format_input(entry)\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index) -> list[int]:\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb6fbc",
   "metadata": {},
   "source": [
    "## Custom collate function\n",
    "\n",
    "Passing in a custom collate function lets us easily pad out shorter sequences in each batch to match the longest one.\n",
    "Initially, the padding token will be `<|endoftext|>`, but we'll eventually set it up so that there's only one EOT token\n",
    "and the padding will be done with `-100`.\n",
    "\n",
    "The collate function is responsible for:\n",
    "1. Finding the longest sequence in the batch\n",
    "2. Padding and preparing inputs\n",
    "3. Removing the extra EOT tokens\n",
    "4. Converting the token list to a tensor and transferring it to the target device.\n",
    "\n",
    "\n",
    "### We're not masking the instructions\n",
    "\n",
    "We could use `-100` to mask out the instructions from each example. That would avoid rewarding the model for memorizing\n",
    "worthless bits like \"Below is a taskâ€¦\", and some people think that's helpful. But it's controversial, and there's at least\n",
    "one paper, [\"Instruction Tuning with Loss Over Instructions,\"](https://arxiv.org/abs/2405.14394) that argues that it's\n",
    "better to train on the whole thing.\n",
    "\n",
    "Maybe I'll try adding instruction masking later, but for now it's not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36bb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "        batch: list[list[int]],\n",
    "        pad_token_id: int=50256, # i.e., <|endoftext|>\n",
    "        ignore_index: int=-100, # this is the default ignore index for torch.nn.CrossEntropyLoss\n",
    "        allowed_max_length: int|None=None,\n",
    "        device: str|torch.device=\"cpu\"\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    batch_max_length = max([len(item)+1 for item in batch])\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id # tensor([bool * max_length])\n",
    "        indices = torch.nonzero(mask).squeeze() # type:ignore\n",
    "        if indices.numel() > 1:\n",
    "            # Note: we only do this -100 thing in the targets tensor\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn, device=get_device(), allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466eb49",
   "metadata": {},
   "source": [
    "## Create the Datasets and DataLoaders\n",
    "\n",
    "As a reminder:\n",
    "- **Dataset**: a class that exposes `__getitem__` and `__len__`, so it's like\n",
    "  a list or a vector. It's not really specialized for anything in particular, it's\n",
    "  just a convenient way to wrap data from some source.\n",
    "- **DataLoader**: a class that encapsulates logic for ordering (shuffle or not),\n",
    "  associating inputs with targets, batching, parallelization, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e821471",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "gpt.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn, # ah, makes sense how partial would be useful now\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f552587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n",
      "355M model loaded.\n"
     ]
    }
   ],
   "source": [
    "gpt355m = openai.load_openai_model(openai.GPT_CONFIG_355M, \"355M\").model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a30fe9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_loss': 3.787, 'validation_loss': 2.2931, 'tokens_seen': 640, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe distance between your right hand and your index finger', 'learning_rate': 0.0001}\n",
      "{'training_loss': 1.3401, 'validation_loss': 1.1385, 'tokens_seen': 3288, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe equation is\\n\\ndendrite\\n\\n', 'learning_rate': 0.0005267241379310345}\n",
      "{'training_loss': 0.9246, 'validation_loss': 1.395, 'tokens_seen': 6008, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n2, 9, 12, 21, 23,', 'learning_rate': 0.0009534482758620692}\n",
      "{'training_loss': 1.6709, 'validation_loss': 1.9618, 'tokens_seen': 8984, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe equation is the equation that appropriately completes the request', 'learning_rate': 0.0013801724137931038}\n",
      "{'training_loss': 2.8485, 'validation_loss': 3.6131, 'tokens_seen': 11552, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe formula for calculating how to calculating the formula for', 'learning_rate': 0.0018068965517241383}\n",
      "{'training_loss': 2.5319, 'validation_loss': 2.9635, 'tokens_seen': 14304, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n### Instruction:\\n\\n\\n\\n\\n\\n\\n', 'learning_rate': 0.0022336206896551723}\n",
      "{'training_loss': 2.7383, 'validation_loss': 2.259, 'tokens_seen': 17256, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe is the chef was, food is cooked by', 'learning_rate': 0.0026603448275862073}\n",
      "{'training_loss': 3.9454, 'validation_loss': 3.2322, 'tokens_seen': 19928, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe process of the two market I storm of the', 'learning_rate': 0.0030870689655172418}\n",
      "{'training_loss': 4.3164, 'validation_loss': 3.1492, 'tokens_seen': 22656, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe device:\\nA and cm to a that', 'learning_rate': 0.0035137931034482763}\n",
      "{'training_loss': 3.183, 'validation_loss': 2.9131, 'tokens_seen': 25368, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nAn decimal.\\nCombvert is\\n### Response', 'learning_rate': 0.003940517241379311}\n",
      "{'training_loss': 3.9984, 'validation_loss': 3.1147, 'tokens_seen': 28312, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n2.', 'learning_rate': 0.004367241379310345}\n",
      "{'training_loss': 3.1965, 'validation_loss': 2.6747, 'tokens_seen': 31104, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n\\nThe following task.', 'learning_rate': 0.004793965517241381}\n",
      "{'training_loss': 2.5159, 'validation_loss': 2.6911, 'tokens_seen': 33904, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nAn is a.', 'learning_rate': 0.005220689655172415}\n",
      "{'training_loss': 2.8074, 'validation_loss': 2.4443, 'tokens_seen': 36816, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe very fast and cell of this sentence using the', 'learning_rate': 0.00564741379310345}\n",
      "{'training_loss': 2.129, 'validation_loss': 2.4947, 'tokens_seen': 39544, 'example_output': \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe type of the formula is B'.\", 'learning_rate': 0.006074137931034484}\n",
      "{'training_loss': 2.3278, 'validation_loss': 2.3572, 'tokens_seen': 42184, 'example_output': \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe opposite of use either an opposite of 'int\", 'learning_rate': 0.006500862068965519}\n",
      "{'training_loss': 2.2918, 'validation_loss': 2.5131, 'tokens_seen': 45024, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nI had a melting point of 13 degrees?', 'learning_rate': 0.006927586206896553}\n",
      "{'training_loss': 2.09, 'validation_loss': 2.7634, 'tokens_seen': 47608, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nThe main square.', 'learning_rate': 0.007354310344827588}\n",
      "{'training_loss': 3.1013, 'validation_loss': 3.1379, 'tokens_seen': 50448, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n of the main is the Great of the main of', 'learning_rate': 0.007781034482758622}\n",
      "{'training_loss': 3.8509, 'validation_loss': 4.1848, 'tokens_seen': 53264, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n in the response:\\n is3.', 'learning_rate': 0.008207758620689655}\n",
      "{'training_loss': 4.056, 'validation_loss': 3.3231, 'tokens_seen': 56352, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nI areh girl42The clothing girl\\n', 'learning_rate': 0.00863448275862069}\n",
      "{'training_loss': 3.4429, 'validation_loss': 2.7286, 'tokens_seen': 59160, 'example_output': \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n of gold, following ',beaut.'\", 'learning_rate': 0.009061206896551724}\n",
      "{'training_loss': 2.4915, 'validation_loss': 2.9674, 'tokens_seen': 62032, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\n is the.', 'learning_rate': 0.00948793103448276}\n",
      "{'training_loss': 2.8378, 'validation_loss': 2.5451, 'tokens_seen': 64968, 'example_output': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSolve the equation 2 + 2\\n\\n### Response:\\nWater.', 'learning_rate': 0.009914655172413795}\n",
      "Training complete. Steps: 115, tokens: 64968\n"
     ]
    }
   ],
   "source": [
    "example_prompt = format_input({\n",
    "    'instruction': \"Solve the equation 2 + 2\",\n",
    "    'input': '',\n",
    "    'output': ''}, include_response=True)\n",
    "\n",
    "training_config: gpt.GPTTrainingConfig = gpt.DEFAULT_TRAINING_CONFIG.copy()\n",
    "training_config['gradient_clipping'] = True\n",
    "training_config['epochs'] = 5\n",
    "\n",
    "trainer = gpt.GPTModel(cfg=openai.GPT_CONFIG_355M, training_cfg=training_config, model=gpt355m)\n",
    "\n",
    "trainer.train_loader(train_loader, val_loader, example_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "609ddc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instruct(instruction, input='', temperature=0.8):\n",
    "    prompt = format_input({\n",
    "        'instruction': instruction,\n",
    "        'input': input,\n",
    "        'output': '',\n",
    "    }, include_response=True)\n",
    "    result = trainer.prompt(prompt, max_tokens=1024, temperature=temperature)\n",
    "    result = result[len(prompt):]\n",
    "    print(textwrap.fill(result, width=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26fedfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients for approximately?\n"
     ]
    }
   ],
   "source": [
    "instruct(\"Translate into French\", \"Je suis Jean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa72a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
