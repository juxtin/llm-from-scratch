{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "643c7b1d",
   "metadata": {},
   "source": [
    "# Fine tuning the model to make a chat bot\n",
    "\n",
    "This is the big guacamole at the end of the rainbow. We'll be fine tuning one of the OpenAI models to be able to respond sort of like ChatGPT. I think there's an example of trying to do this on the foundation model in `openai.ipynb` without fine-tuning, and right now it _sucks_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aec3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n",
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 10:41:12.236935: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-05 10:41:12.485363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751737272.603859    4099 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751737272.643737    4099 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751737272.885045    4099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751737272.885089    4099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751737272.885094    4099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751737272.885097    4099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-05 10:41:12.900482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import openai # type:ignore\n",
    "import gpt # type:ignore\n",
    "from gpt import get_device # type: ignore\n",
    "import torch\n",
    "import urllib\n",
    "import ssl\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from typing import TypedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "from functools import partial\n",
    "import textwrap\n",
    "from datasets import load_dataset\n",
    "import training # type: ignore\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948a0d4",
   "metadata": {},
   "source": [
    "## Download the instruction training data\n",
    "\n",
    "This is 1,100 instruction-response pairs (actually some have a third field called input) that were made specifically for the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f063394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n",
      "Example:\n",
      "{'input': 'He go to the park every day.',\n",
      " 'instruction': 'Edit the following sentence for grammar.',\n",
      " 'output': 'He goes to the park every day.'}\n"
     ]
    }
   ],
   "source": [
    "class InstructionExample(TypedDict):\n",
    "    instruction: str  # A description of the task to be performed\n",
    "    input: str        # Optional parameter for the task\n",
    "    output: str       # The expected result of performing the task\n",
    "\n",
    "def download_and_load_file(file_path: str, url: str) -> list[InstructionExample]:\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response: # type:ignore\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n",
    "print(\"Example:\")\n",
    "pprint(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab7037",
   "metadata": {},
   "source": [
    "## Convert the examples to Stanford Alpaca format\n",
    "\n",
    "The [format](https://github.com/tatsu-lab/stanford_alpaca) looks like this:\n",
    "\n",
    "```\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "```\n",
    "\n",
    "Or, if there's no input:\n",
    "\n",
    "```\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07052c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry: InstructionExample, include_response:bool=True) -> str:\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    response_text = f\"\\n\\n### Response:\\n{entry['output']}\" if include_response else \"\"\n",
    "\n",
    "    return instruction_text + input_text + response_text\n",
    "\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94965cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data: list[InstructionExample], tokenizer: tiktoken.Encoding):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            full_text = format_input(entry)\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index) -> list[int]:\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb6fbc",
   "metadata": {},
   "source": [
    "## Custom collate function\n",
    "\n",
    "Passing in a custom collate function lets us easily pad out shorter sequences in each batch to match the longest one.\n",
    "Initially, the padding token will be `<|endoftext|>`, but we'll eventually set it up so that there's only one EOT token\n",
    "and the padding will be done with `-100`.\n",
    "\n",
    "The collate function is responsible for:\n",
    "1. Finding the longest sequence in the batch\n",
    "2. Padding and preparing inputs\n",
    "3. Removing the extra EOT tokens\n",
    "4. Converting the token list to a tensor and transferring it to the target device.\n",
    "\n",
    "\n",
    "### We're not masking the instructions\n",
    "\n",
    "We could use `-100` to mask out the instructions from each example. That would avoid rewarding the model for memorizing\n",
    "worthless bits like \"Below is a task…\", and some people think that's helpful. But it's controversial, and there's at least\n",
    "one paper, [\"Instruction Tuning with Loss Over Instructions,\"](https://arxiv.org/abs/2405.14394) that argues that it's\n",
    "better to train on the whole thing.\n",
    "\n",
    "Maybe I'll try adding instruction masking later, but for now it's not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36bb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "        batch: list[list[int]],\n",
    "        pad_token_id: int=50256, # i.e., <|endoftext|>\n",
    "        ignore_index: int=-100, # this is the default ignore index for torch.nn.CrossEntropyLoss\n",
    "        allowed_max_length: int|None=None,\n",
    "        device: str|torch.device=\"cpu\"\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    batch_max_length = max([len(item)+1 for item in batch])\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id # tensor([bool * max_length])\n",
    "        indices = torch.nonzero(mask).squeeze() # type:ignore\n",
    "        if indices.numel() > 1:\n",
    "            # Note: we only do this -100 thing in the targets tensor\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst)\n",
    "    targets_tensor = torch.stack(targets_lst)\n",
    "\n",
    "    return inputs_tensor.to(device), targets_tensor.to(device)\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn, device=get_device(), allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466eb49",
   "metadata": {},
   "source": [
    "## Create the Datasets and DataLoaders\n",
    "\n",
    "As a reminder:\n",
    "- **Dataset**: a class that exposes `__getitem__` and `__len__`, so it's like\n",
    "  a list or a vector. It's not really specialized for anything in particular, it's\n",
    "  just a convenient way to wrap data from some source.\n",
    "- **DataLoader**: a class that encapsulates logic for ordering (shuffle or not),\n",
    "  associating inputs with targets, batching, parallelization, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e821471",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "custom_loader = partial(DataLoader, batch_size=batch_size, collate_fn=customized_collate_fn, shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = custom_loader(train_dataset)\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = custom_loader(val_dataset)\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = custom_loader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30fe9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaExampleGenerator(training.ExampleGenerator):\n",
    "    def __init__(self, instruction: str, input: str = \"\"):\n",
    "        self.prompt = format_input({\n",
    "            'instruction': instruction,\n",
    "            'input': input,\n",
    "            'output': \"\"\n",
    "        }, include_response=True)\n",
    "    \n",
    "    def generate(self, model: gpt.GPTModel) -> str:\n",
    "        result = training.text_completion_topk(model, initial_context=self.prompt, max_new_tokens=128, context_size=512, topk=50, temperature=1.5)\n",
    "        return result[len(self.prompt):].strip()\n",
    "\n",
    "def train_model_on_small_example_set(model: gpt.GPTModel):\n",
    "    example_prompt = format_input({\n",
    "        'instruction': \"Convert this sentence to passive voice.\",\n",
    "        'input': 'The chef cooked the meal.',\n",
    "        'output': ''}, include_response=True)\n",
    "\n",
    "    training_config = training.new_training_config(\n",
    "        gradient_clipping = False,\n",
    "        epochs = 2,\n",
    "        peak_lr = 5e-5,\n",
    "        initial_lr = 4e-6,\n",
    "        eval_freq = 30,\n",
    "    )\n",
    "\n",
    "    optimizer = training.default_optimizer(model, training_config)\n",
    "\n",
    "    training.train(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        training_loader=train_loader,\n",
    "        validation_loader=val_loader,\n",
    "        cfg=training_config,\n",
    "        metrics=training.StdoutMetrics(print_interval=30),\n",
    "        example_generator=LlamaExampleGenerator(instruction=\"Use this word in a sentence\", input=\"fascinating\")\n",
    "    )\n",
    "\n",
    "# gpt355m = openai.load_openai_model(openai.GPT_CONFIG_355M, \"355M\")\n",
    "# train_model_on_small_example_set(gpt355m)\n",
    "# model = gpt355m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88817a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: \"epoch size\"=116\n",
      "Parameter: \"epochs\"=2\n",
      "Parameter: \"total training size\"=232\n",
      "Parameter: \"validation size\"=6\n",
      "Parameter: \"gradient clipping\"=False\n",
      "[30] Metric: \"training loss\"=3.9355931282043457\n",
      "[30] Metric: \"learning rate\"=4.986173490981773e-05\n",
      "[30] Metric: \"tokens seen\"=16872\n",
      "[30] Metric: \"epoch\"=0\n",
      "[30] Metric: \"progress percent\"=12.931034482758621\n",
      "[30] Example (example): \"Texts have three sentences.--Article\n",
      "Column 4 × 5 × 1/2 × 1 × 10 × $1/2 × 19 × 1/3 × 1/8 × 1/1/2 × 3)/8 × 2/8/8/834 Amount 0/1/5/1006 ounce. 2003 Solution 10/0/10/2009 cents. Included § 1/2 × 7/908 Amount 1/6/832/4/0/506/1/2/0/2 × 13/6 ounce. ¶ Section 1/2/833/5/039\"\n",
      "[30] Metric: \"validation loss\"=3.604365110397339\n",
      "[60] Metric: \"training loss\"=2.2944719791412354\n",
      "[60] Metric: \"learning rate\"=4.6232121380780034e-05\n",
      "[60] Metric: \"tokens seen\"=34264\n",
      "[60] Metric: \"epoch\"=0\n",
      "[60] Metric: \"progress percent\"=25.862068965517242\n",
      "[60] Example (example): \"Definitions:\n",
      "Definitions:\n",
      "\n",
      " Input:\n",
      "Defative, obsittal. Microphoneium.\n",
      "\n",
      "cific: [Pref; pref. ambassada. ambassada.]\n",
      "\n",
      "�IZE: [This], a form or form derived [between together]. Italikion; cf. Ïculiar’ (?)\n",
      "\n",
      "Chemnica.\n",
      "\n",
      " homeworkiated; (Med.)\n",
      "\n",
      " nuclei. (Geometrical.)\n",
      "\n",
      "Defuration: 1. Erecton; Ïcyrhe.\n",
      "\n",
      " breakup:\n",
      "\n",
      " (a) Cementis. 3. (Zo\"\n",
      "[60] Metric: \"validation loss\"=2.3528194427490234\n",
      "[90] Metric: \"training loss\"=2.367391347885132\n",
      "[90] Metric: \"learning rate\"=3.8357573446201825e-05\n",
      "[90] Metric: \"tokens seen\"=51032\n",
      "[90] Metric: \"epoch\"=0\n",
      "[90] Metric: \"progress percent\"=38.793103448275865\n",
      "[90] Example (example): \"My son has made you marry me.\n",
      "\n",
      " microbialaturation:\n",
      "If you promise me it shall be, and you have not a better means than me. Take a child or me.\"\n",
      "[90] Metric: \"validation loss\"=2.042156457901001\n",
      "[120] Metric: \"training loss\"=1.9594027996063232\n",
      "[120] Metric: \"learning rate\"=2.781244813127552e-05\n",
      "[120] Metric: \"tokens seen\"=67776\n",
      "[120] Metric: \"epoch\"=1\n",
      "[120] Metric: \"progress percent\"=51.724137931034484\n",
      "[120] Example (example): \"Grape your word a man, and for a man in the world, a man in the realm would not choose to choose to suit themselves or to make such a choice of himself.\n",
      "\n",
      " \\\\ ..........:\n",
      "Why should my word be called [fautilon].aptop Response:\n",
      "He never gave a thought to me before at all. SWAT were granted and said he never could ever, never could it again be. dystopian US did not exist when they said this word but the truth (and) the fact that if I had not been in our company with the woman I would be inclined. Write your letter to your servant and ask\"\n",
      "[120] Metric: \"validation loss\"=1.9077390829722087\n",
      "[150] Metric: \"training loss\"=1.658961296081543\n",
      "[150] Metric: \"learning rate\"=1.670503054125621e-05\n",
      "[150] Metric: \"tokens seen\"=84792\n",
      "[150] Metric: \"epoch\"=1\n",
      "[150] Metric: \"progress percent\"=64.65517241379311\n",
      "[150] Example (example): \"He who saw the light He would see would be on our path.\"### Response:\n",
      "\"The light is down for him.\" ecosystems554: \"The light is overhe could always be reflected by the dark!\" totalitarianoline explained this question.\"\n",
      "[150] Metric: \"validation loss\"=1.7294272184371948\n",
      "[180] Metric: \"training loss\"=1.6291049718856812\n",
      "[180] Metric: \"learning rate\"=7.256024780033418e-06\n",
      "[180] Metric: \"tokens seen\"=101432\n",
      "[180] Metric: \"epoch\"=1\n",
      "[180] Metric: \"progress percent\"=77.58620689655173\n",
      "[180] Example (example): \"The temperature in the gas is 100 degrees. neutron: -oxitating to 78 grains will present 80. ecosystem: -oxiving to 69 ounces will then appear in 100 places.### Response: -oxicating is 98 times00 cents. ecosystems: -phasing is 26 degrees. bloodstream: -orgaining would be 0.1985: -oxating is 100 times that.が: -rodcing, approximately equal parts. bloodstream: -oxology should present 300 feet.global: -rasitating a 25 degrees. Response: temperature in gas is 106 deg.-ΚΛΟΥΣΤΚ\"\n",
      "[180] Metric: \"validation loss\"=1.7500685254732768\n",
      "[210] Metric: \"training loss\"=1.765782356262207\n",
      "[210] Metric: \"learning rate\"=1.3545689574841342e-06\n",
      "[210] Metric: \"tokens seen\"=117904\n",
      "[210] Metric: \"epoch\"=1\n",
      "[210] Metric: \"progress percent\"=90.51724137931035\n",
      "[210] Example (example): \"Arranged in a phrase.\n",
      "\n",
      " Input:\n",
      "Arranged in the form of 'bessified' into 'bessured'.\n",
      "\n",
      "### Coord:\n",
      "The name as that refers to 'bessolved'.### Terrorism: (_Arranged in Theobites isles, male and male (seriously equivalent). Typically (_Herbs, male and female. insightful): _Arranged theobites and malevolent mammals, female or female.�]\n",
      "\n",
      " Response:\n",
      "Conformed to the chimpanzee to man.い):\n",
      "Theobites--Chronounced into [Theobites.] Same for theob\"\n",
      "[210] Metric: \"validation loss\"=1.7175829609235127\n",
      "Training finished successfully: final validation loss 1.703\n"
     ]
    }
   ],
   "source": [
    "# GPT_CONFIG_MEDIUM: gpt.GPTConfigDict = {**gpt.GPT_CONFIG_124M, \"context_length\": 512} # Equivalent to the project gutenberg config\n",
    "# model = gpt.GPTModel(GPT_CONFIG_MEDIUM)\n",
    "\n",
    "# training.load(model=model, optimizer=None, name=\"pg19_runpod_355m_396\")\n",
    "# train_model_on_small_example_set(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609ddc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct_str can be used in cases where you need to keep the string around\n",
    "def instruct_str(model: gpt.GPTModel, instruction: str, input='', temperature=0.8) -> str:\n",
    "    prompt = format_input({\n",
    "        'instruction': instruction,\n",
    "        'input': input,\n",
    "        'output': '',\n",
    "    }, include_response=True)\n",
    "    result = training.text_completion_topk(model, initial_context=prompt, max_new_tokens=1024, context_size=512, topk=50, temperature=temperature)\n",
    "    return result[len(prompt):].strip()\n",
    "\n",
    "# instruct is just used interactively, so it prints the result nicely\n",
    "def instruct(trainer: gpt.GPTModel, instruction: str, input='', temperature=0.8):\n",
    "    result = instruct_str(trainer, instruction, input, temperature)\n",
    "    print(textwrap.fill(result, width=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fedfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name six chariots, chariots, chariots, chariots, chariots, and chariots.  ### Response: They are chariots, chariots,\n",
      "chariots, chariots, chariots, chariots, chariots, chariots, chariots, chariots, chariots, char chariots.  ### Response:\n",
      "The chariots and chariots of chariots are chariots and chariots.   kg Response: The chariots of chariots and chariots\n",
      "are chariots.\n"
     ]
    }
   ],
   "source": [
    "# Should output: The healthier of the two foods is carrots.\n",
    "\n",
    "# instruct(model, \"Describe a pastoral scene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc4e40",
   "metadata": {},
   "source": [
    "# Training on Alpaca\n",
    "\n",
    "The [tatsu-lab/alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) dataset is about 52k rows, so almost 50x bigger than the one we just trained on. That should give 50x better results, right???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92dd9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = load_dataset(\"tatsu-lab/alpaca\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f4c15b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_len(txt: str):\n",
    "    tks = tokenizer.encode(txt)\n",
    "    return len(tks)\n",
    "\n",
    "alpaca: list[InstructionExample] = [x for x in alpaca if token_len(x['text']) <= 323] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d13829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 48915\n",
      "Val: 102\n",
      "Test: 2473\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "alpaca_train_portion = int(len(alpaca) * 0.95)\n",
    "alpaca_val_portion = int(len(alpaca) * 0.002) # about 100 examples\n",
    "alpaca_test_portion = len(alpaca) - alpaca_train_portion - alpaca_val_portion\n",
    "\n",
    "alpaca_train_data = alpaca[:alpaca_train_portion]\n",
    "alpaca_test_data = alpaca[alpaca_train_portion:alpaca_train_portion + alpaca_test_portion]\n",
    "alpaca_val_data = alpaca[alpaca_train_portion + alpaca_test_portion:]\n",
    "\n",
    "alpaca_train_dataset = InstructionDataset(alpaca_train_data, tokenizer)\n",
    "alpaca_test_dataset = InstructionDataset(alpaca_test_data, tokenizer)\n",
    "alpaca_val_dataset = InstructionDataset(alpaca_val_data, tokenizer)\n",
    "\n",
    "print(f\"Train: {len(alpaca_train_data)}\")\n",
    "print(f\"Val: {len(alpaca_val_data)}\")\n",
    "print(f\"Test: {len(alpaca_test_data)}\")\n",
    "\n",
    "alpaca_train = DataLoader(\n",
    "    alpaca_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "alpaca_test = DataLoader(\n",
    "    alpaca_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "alpaca_val = DataLoader(\n",
    "    alpaca_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: \"epoch size\"=48915\n",
      "Parameter: \"epochs\"=2\n",
      "Parameter: \"total training size\"=97830\n",
      "Parameter: \"validation size\"=102\n",
      "Parameter: \"gradient clipping\"=False\n",
      "[30] Metric: \"training loss\"=1.4460192918777466\n",
      "[30] Metric: \"learning rate\"=1.5332720024532352e-07\n",
      "[30] Metric: \"tokens seen\"=3353\n",
      "[30] Metric: \"epoch\"=0\n",
      "[30] Metric: \"progress percent\"=0.030665440049064706\n",
      "[60] Metric: \"training loss\"=3.613281726837158\n",
      "[60] Metric: \"learning rate\"=3.0665440049064705e-07\n",
      "[60] Metric: \"tokens seen\"=6157\n",
      "[60] Metric: \"epoch\"=0\n",
      "[60] Metric: \"progress percent\"=0.06133088009812941\n",
      "[90] Metric: \"training loss\"=4.144659042358398\n",
      "[90] Metric: \"learning rate\"=4.5998160073597057e-07\n",
      "[90] Metric: \"tokens seen\"=8966\n",
      "[90] Metric: \"epoch\"=0\n",
      "[90] Metric: \"progress percent\"=0.09199632014719411\n",
      "[120] Metric: \"training loss\"=5.755926132202148\n",
      "[120] Metric: \"learning rate\"=6.133088009812941e-07\n",
      "[120] Metric: \"tokens seen\"=12233\n",
      "[120] Metric: \"epoch\"=0\n",
      "[120] Metric: \"progress percent\"=0.12266176019625882\n",
      "[150] Metric: \"training loss\"=4.160099506378174\n",
      "[150] Metric: \"learning rate\"=7.666360012266176e-07\n",
      "[150] Metric: \"tokens seen\"=15198\n",
      "[150] Metric: \"epoch\"=0\n",
      "[150] Metric: \"progress percent\"=0.1533272002453235\n",
      "[180] Metric: \"training loss\"=4.365693092346191\n",
      "[180] Metric: \"learning rate\"=9.199632014719411e-07\n",
      "[180] Metric: \"tokens seen\"=18288\n",
      "[180] Metric: \"epoch\"=0\n",
      "[180] Metric: \"progress percent\"=0.18399264029438822\n",
      "[200] Example (example): \"He asks of no questions.\n",
      "\n",
      "### proble:\n",
      "A question for me is a question whether--what is it he means, if he thinks?\n",
      "\n",
      " neutron353]:\n",
      "Has he given up all his doubts.### Coord: we don't believe so. ecosystems: he told you.### ecosystem: you and it always is in such a way that people can't take the place and then and always do a thing for nobody. ethanolively: I don't go there. Response: you don't deny it. Verify.: we haven't the use in talking.### PM: you are always coming out of this house.\"\n",
      "[210] Metric: \"training loss\"=4.952077865600586\n",
      "[210] Metric: \"learning rate\"=1.0732904017172647e-06\n",
      "[210] Metric: \"tokens seen\"=21562\n",
      "[210] Metric: \"epoch\"=0\n",
      "[210] Metric: \"progress percent\"=0.21465808034345293\n",
      "[240] Metric: \"training loss\"=4.068817615509033\n",
      "[240] Metric: \"learning rate\"=1.2266176019625882e-06\n",
      "[240] Metric: \"tokens seen\"=24955\n",
      "[240] Metric: \"epoch\"=0\n",
      "[240] Metric: \"progress percent\"=0.24532352039251765\n",
      "[270] Metric: \"training loss\"=4.279136657714844\n",
      "[270] Metric: \"learning rate\"=1.3799448022079117e-06\n",
      "[270] Metric: \"tokens seen\"=28075\n",
      "[270] Metric: \"epoch\"=0\n",
      "[270] Metric: \"progress percent\"=0.27598896044158233\n",
      "[300] Metric: \"training loss\"=1.8990932703018188\n",
      "[300] Metric: \"learning rate\"=1.5332720024532351e-06\n",
      "[300] Metric: \"tokens seen\"=30947\n",
      "[300] Metric: \"epoch\"=0\n",
      "[300] Metric: \"progress percent\"=0.306654400490647\n",
      "[330] Metric: \"training loss\"=4.0706095695495605\n",
      "[330] Metric: \"learning rate\"=1.6865992026985588e-06\n",
      "[330] Metric: \"tokens seen\"=33844\n",
      "[330] Metric: \"epoch\"=0\n",
      "[330] Metric: \"progress percent\"=0.33731984053971176\n",
      "[360] Metric: \"training loss\"=5.03245735168457\n",
      "[360] Metric: \"learning rate\"=1.8399264029438823e-06\n",
      "[360] Metric: \"tokens seen\"=37073\n",
      "[360] Metric: \"epoch\"=0\n",
      "[360] Metric: \"progress percent\"=0.36798528058877644\n",
      "[390] Metric: \"training loss\"=4.074761867523193\n",
      "[390] Metric: \"learning rate\"=1.993253603189206e-06\n",
      "[390] Metric: \"tokens seen\"=40379\n",
      "[390] Metric: \"epoch\"=0\n",
      "[390] Metric: \"progress percent\"=0.3986507206378411\n",
      "[400] Example (example): \"The text of these sentence is 1.6.txt\n",
      "3.025.524.432.00/18.29.07.10.04.03.10.50.00.00.60.00.28.19.00.50 -------28.0.50;50 6.00 -------29.25.00.00 (Illustration: FIG: FIG: FIG: FIG: FIG: FIG: FIG.:://www.gutenberghtm)=Defectiveored figure as the picture and painting of a great family being erected.こ.432.29.70).00.50; 1900.\"\n",
      "[420] Metric: \"training loss\"=4.562216281890869\n",
      "[420] Metric: \"learning rate\"=2.1465808034345294e-06\n",
      "[420] Metric: \"tokens seen\"=43537\n",
      "[420] Metric: \"epoch\"=0\n",
      "[420] Metric: \"progress percent\"=0.42931616068690587\n",
      "[450] Metric: \"training loss\"=6.519843578338623\n",
      "[450] Metric: \"learning rate\"=2.299908003679853e-06\n",
      "[450] Metric: \"tokens seen\"=47137\n",
      "[450] Metric: \"epoch\"=0\n",
      "[450] Metric: \"progress percent\"=0.45998160073597055\n",
      "[480] Metric: \"training loss\"=2.433967351913452\n",
      "[480] Metric: \"learning rate\"=2.4532352039251764e-06\n",
      "[480] Metric: \"tokens seen\"=50355\n",
      "[480] Metric: \"epoch\"=0\n",
      "[480] Metric: \"progress percent\"=0.4906470407850353\n",
      "[510] Metric: \"training loss\"=2.992356300354004\n",
      "[510] Metric: \"learning rate\"=2.6065624041705003e-06\n",
      "[510] Metric: \"tokens seen\"=53502\n",
      "[510] Metric: \"epoch\"=0\n",
      "[510] Metric: \"progress percent\"=0.5213124808341\n",
      "[540] Metric: \"training loss\"=2.032853364944458\n",
      "[540] Metric: \"learning rate\"=2.7598896044158233e-06\n",
      "[540] Metric: \"tokens seen\"=57350\n",
      "[540] Metric: \"epoch\"=0\n",
      "[540] Metric: \"progress percent\"=0.5519779208831647\n",
      "[570] Metric: \"training loss\"=2.640519618988037\n",
      "[570] Metric: \"learning rate\"=2.9132168046611468e-06\n",
      "[570] Metric: \"tokens seen\"=60541\n",
      "[570] Metric: \"epoch\"=0\n",
      "[570] Metric: \"progress percent\"=0.5826433609322293\n",
      "[600] Metric: \"training loss\"=3.1157119274139404\n",
      "[600] Metric: \"learning rate\"=3.0665440049064703e-06\n",
      "[600] Metric: \"tokens seen\"=63386\n",
      "[600] Metric: \"epoch\"=0\n",
      "[600] Metric: \"progress percent\"=0.613308800981294\n",
      "[600] Example (example): \"All that can happen by a person interested and interested.\n",
      "\n",
      "り=-=-=- Chapter III\n",
      "\n",
      "Release this listless, a living personage in a cave was born the next one. Any examination of the cave near to place was made a material.�://books.###/\"**FOREWORDALITY (to use this name).くFOREWORDALence (to use it a adjective).aptop�ELYAL (-hymti*n\") were brought to it in this way.###[]\n",
      "\n",
      "### Response:\n",
      "Ezekikado is probably dead.帏� -sy\n",
      "\n",
      "う (-h\"\n",
      "[600] Metric: \"validation loss\"=3.540731096968931\n",
      "[630] Metric: \"training loss\"=3.8997802734375\n",
      "[630] Metric: \"learning rate\"=3.219871205151794e-06\n",
      "[630] Metric: \"tokens seen\"=66603\n",
      "[630] Metric: \"epoch\"=0\n",
      "[630] Metric: \"progress percent\"=0.6439742410303588\n",
      "[660] Metric: \"training loss\"=3.6149020195007324\n",
      "[660] Metric: \"learning rate\"=3.3731984053971176e-06\n",
      "[660] Metric: \"tokens seen\"=70043\n",
      "[660] Metric: \"epoch\"=0\n",
      "[660] Metric: \"progress percent\"=0.6746396810794235\n",
      "[690] Metric: \"training loss\"=4.548749923706055\n",
      "[690] Metric: \"learning rate\"=3.526525605642441e-06\n",
      "[690] Metric: \"tokens seen\"=72853\n",
      "[690] Metric: \"epoch\"=0\n",
      "[690] Metric: \"progress percent\"=0.7053051211284882\n",
      "[720] Metric: \"training loss\"=4.6326704025268555\n",
      "[720] Metric: \"learning rate\"=3.6798528058877646e-06\n",
      "[720] Metric: \"tokens seen\"=76306\n",
      "[720] Metric: \"epoch\"=0\n",
      "[720] Metric: \"progress percent\"=0.7359705611775529\n",
      "[750] Metric: \"training loss\"=3.888723850250244\n",
      "[750] Metric: \"learning rate\"=3.833180006133088e-06\n",
      "[750] Metric: \"tokens seen\"=79166\n",
      "[750] Metric: \"epoch\"=0\n",
      "[750] Metric: \"progress percent\"=0.7666360012266176\n",
      "[780] Metric: \"training loss\"=3.490108013153076\n",
      "[780] Metric: \"learning rate\"=3.986507206378412e-06\n",
      "[780] Metric: \"tokens seen\"=82630\n",
      "[780] Metric: \"epoch\"=0\n",
      "[780] Metric: \"progress percent\"=0.7973014412756823\n",
      "[800] Example (example): \"The following sentence may be compared to that of restricting others,\n",
      "\n",
      "text (Information). Project Gutenberg also includes the hyphenological Archive.txt@x1/3/32.0037 or50\n",
      "1907 (http:// Gutenberg is@x944 [Title/files@ton3/0179] encoding (https://archive).\n",
      " Images of a text can possibly be changed out of that word;**]Transcriber's note that each note be changed before downloading and punctually******** (https://archive.net). 2003 has an HTML version:\n",
      "fagmatic\n",
      " -plesi, http://www.\"\n",
      "[810] Metric: \"training loss\"=3.949009895324707\n",
      "[810] Metric: \"learning rate\"=4.139834406623736e-06\n",
      "[810] Metric: \"tokens seen\"=85906\n",
      "[810] Metric: \"epoch\"=0\n",
      "[810] Metric: \"progress percent\"=0.8279668813247469\n",
      "[840] Metric: \"training loss\"=3.0371885299682617\n",
      "[840] Metric: \"learning rate\"=4.293161606869059e-06\n",
      "[840] Metric: \"tokens seen\"=89282\n",
      "[840] Metric: \"epoch\"=0\n",
      "[840] Metric: \"progress percent\"=0.8586323213738117\n",
      "[870] Metric: \"training loss\"=3.624208927154541\n",
      "[870] Metric: \"learning rate\"=4.446488807114382e-06\n",
      "[870] Metric: \"tokens seen\"=92248\n",
      "[870] Metric: \"epoch\"=0\n",
      "[870] Metric: \"progress percent\"=0.8892977614228765\n",
      "[900] Metric: \"training loss\"=4.032970428466797\n",
      "[900] Metric: \"learning rate\"=4.599816007359706e-06\n",
      "[900] Metric: \"tokens seen\"=95556\n",
      "[900] Metric: \"epoch\"=0\n",
      "[900] Metric: \"progress percent\"=0.9199632014719411\n",
      "[930] Metric: \"training loss\"=3.0485870838165283\n",
      "[930] Metric: \"learning rate\"=4.753143207605029e-06\n",
      "[930] Metric: \"tokens seen\"=98774\n",
      "[930] Metric: \"epoch\"=0\n",
      "[930] Metric: \"progress percent\"=0.9506286415210058\n",
      "[960] Metric: \"training loss\"=3.4497621059417725\n",
      "[960] Metric: \"learning rate\"=4.906470407850353e-06\n",
      "[960] Metric: \"tokens seen\"=101908\n",
      "[960] Metric: \"epoch\"=0\n",
      "[960] Metric: \"progress percent\"=0.9812940815700706\n",
      "[990] Metric: \"training loss\"=3.8258144855499268\n",
      "[990] Metric: \"learning rate\"=5.059797608095677e-06\n",
      "[990] Metric: \"tokens seen\"=105140\n",
      "[990] Metric: \"epoch\"=0\n",
      "[990] Metric: \"progress percent\"=1.011959521619135\n",
      "[1000] Example (example): \"We can easily carry up any more definite definition of our origin, the theory of our inheritance as long future history as history, life, ideals, ideal life and environment of life. Describe here what the idealism may lead. Read the idealism, that it is of all things, which are but possible, but not of mere intelligence. We may say \"fascusing\" [The Absoluteism is very readable].\n",
      "\n",
      " globalasticism follows by restricting differences, so much the same will become its universal nature. Words given in time form and symbolical in their sentence indicates its personal identity of one thing. Other phrases occur for\"\n",
      "[1020] Metric: \"training loss\"=2.1840991973876953\n",
      "[1020] Metric: \"learning rate\"=5.2131248083410005e-06\n",
      "[1020] Metric: \"tokens seen\"=108172\n",
      "[1020] Metric: \"epoch\"=0\n",
      "[1020] Metric: \"progress percent\"=1.0426249616682\n",
      "[1050] Metric: \"training loss\"=3.715714693069458\n",
      "[1050] Metric: \"learning rate\"=5.366452008586324e-06\n",
      "[1050] Metric: \"tokens seen\"=110878\n",
      "[1050] Metric: \"epoch\"=0\n",
      "[1050] Metric: \"progress percent\"=1.0732904017172646\n",
      "[1080] Metric: \"training loss\"=3.252105474472046\n",
      "[1080] Metric: \"learning rate\"=5.519779208831647e-06\n",
      "[1080] Metric: \"tokens seen\"=114647\n",
      "[1080] Metric: \"epoch\"=0\n",
      "[1080] Metric: \"progress percent\"=1.1039558417663293\n",
      "[1110] Metric: \"training loss\"=2.9997124671936035\n",
      "[1110] Metric: \"learning rate\"=5.6731064090769705e-06\n",
      "[1110] Metric: \"tokens seen\"=117796\n",
      "[1110] Metric: \"epoch\"=0\n",
      "[1110] Metric: \"progress percent\"=1.134621281815394\n",
      "[1140] Metric: \"training loss\"=4.7233781814575195\n",
      "[1140] Metric: \"learning rate\"=5.8264336093222936e-06\n",
      "[1140] Metric: \"tokens seen\"=120743\n",
      "[1140] Metric: \"epoch\"=0\n",
      "[1140] Metric: \"progress percent\"=1.1652867218644587\n",
      "[1170] Metric: \"training loss\"=4.6127519607543945\n",
      "[1170] Metric: \"learning rate\"=5.9797608095676175e-06\n",
      "[1170] Metric: \"tokens seen\"=123614\n",
      "[1170] Metric: \"epoch\"=0\n",
      "[1170] Metric: \"progress percent\"=1.1959521619135236\n",
      "[1200] Metric: \"training loss\"=4.596658229827881\n",
      "[1200] Metric: \"learning rate\"=6.1330880098129405e-06\n",
      "[1200] Metric: \"tokens seen\"=126952\n",
      "[1200] Metric: \"epoch\"=0\n",
      "[1200] Metric: \"progress percent\"=1.226617601962588\n",
      "[1200] Example (example): \"All the spaces in a book-system differ essentially in this book. Each book makes a perfect list (Figure images).://stretches/the\n",
      "\n",
      "### Response:\n",
      "These atoms are made available to us through a single book. 2003 of matter indicate a volume or a page or an Initial Series. Please apply a term to a class into the whole page and the book is a capital letter in fact of any number. When the letters are given in print from any center of room cover, either out of place use (see Figure 87 with pages 12 and 1), I answer the question.\n",
      "\n",
      "### Response:\n",
      "The same\"\n",
      "[1200] Metric: \"validation loss\"=3.3931329121776654\n",
      "[1230] Metric: \"training loss\"=1.4664738178253174\n",
      "[1230] Metric: \"learning rate\"=6.286415210058265e-06\n",
      "[1230] Metric: \"tokens seen\"=130092\n",
      "[1230] Metric: \"epoch\"=0\n",
      "[1230] Metric: \"progress percent\"=1.2572830420116528\n",
      "[1260] Metric: \"training loss\"=2.513155937194824\n",
      "[1260] Metric: \"learning rate\"=6.439742410303588e-06\n",
      "[1260] Metric: \"tokens seen\"=133565\n",
      "[1260] Metric: \"epoch\"=0\n",
      "[1260] Metric: \"progress percent\"=1.2879484820607177\n",
      "[1290] Metric: \"training loss\"=4.277556896209717\n",
      "[1290] Metric: \"learning rate\"=6.593069610548911e-06\n",
      "[1290] Metric: \"tokens seen\"=136908\n",
      "[1290] Metric: \"epoch\"=0\n",
      "[1290] Metric: \"progress percent\"=1.3186139221097823\n",
      "[1320] Metric: \"training loss\"=3.3463799953460693\n",
      "[1320] Metric: \"learning rate\"=6.746396810794235e-06\n",
      "[1320] Metric: \"tokens seen\"=139932\n",
      "[1320] Metric: \"epoch\"=0\n",
      "[1320] Metric: \"progress percent\"=1.349279362158847\n",
      "[1350] Metric: \"training loss\"=4.5694074630737305\n",
      "[1350] Metric: \"learning rate\"=6.899724011039558e-06\n",
      "[1350] Metric: \"tokens seen\"=143715\n",
      "[1350] Metric: \"epoch\"=0\n",
      "[1350] Metric: \"progress percent\"=1.3799448022079117\n",
      "[1380] Metric: \"training loss\"=2.088294506072998\n",
      "[1380] Metric: \"learning rate\"=7.053051211284882e-06\n",
      "[1380] Metric: \"tokens seen\"=146434\n",
      "[1380] Metric: \"epoch\"=0\n",
      "[1380] Metric: \"progress percent\"=1.4106102422569764\n",
      "[1400] Example (example): \"Fied for a game was fainty, and fidgetty. ecosystems ------------+-----------\n",
      "\n",
      "### Response:\n",
      "Fied for a year 'boulding a game' broke down and went a short distance to a club one day on mired fellows in white musings overcoat clothes, the children outwitted a girl in small blue shirt socks! This old habit of clothes has no appearance, as a circus is but fair clothes of great distinction and is still less beautiful. Finally, when a boy is big enough by his long arms, his hands, his long coat collar and his wide collar of white frock\"\n",
      "[1410] Metric: \"training loss\"=4.819541931152344\n",
      "[1410] Metric: \"learning rate\"=7.206378411530205e-06\n",
      "[1410] Metric: \"tokens seen\"=149467\n",
      "[1410] Metric: \"epoch\"=0\n",
      "[1410] Metric: \"progress percent\"=1.441275682306041\n",
      "[1440] Metric: \"training loss\"=2.575874090194702\n",
      "[1440] Metric: \"learning rate\"=7.359705611775529e-06\n",
      "[1440] Metric: \"tokens seen\"=152596\n",
      "[1440] Metric: \"epoch\"=0\n",
      "[1440] Metric: \"progress percent\"=1.4719411223551058\n",
      "[1470] Metric: \"training loss\"=5.444626331329346\n",
      "[1470] Metric: \"learning rate\"=7.513032812020852e-06\n",
      "[1470] Metric: \"tokens seen\"=156024\n",
      "[1470] Metric: \"epoch\"=0\n",
      "[1470] Metric: \"progress percent\"=1.5026065624041705\n",
      "[1500] Metric: \"training loss\"=4.439736366271973\n",
      "[1500] Metric: \"learning rate\"=7.666360012266176e-06\n",
      "[1500] Metric: \"tokens seen\"=159137\n",
      "[1500] Metric: \"epoch\"=0\n",
      "[1500] Metric: \"progress percent\"=1.5332720024532351\n",
      "[1530] Metric: \"training loss\"=4.171272277832031\n",
      "[1530] Metric: \"learning rate\"=7.8196872125115e-06\n",
      "[1530] Metric: \"tokens seen\"=162497\n",
      "[1530] Metric: \"epoch\"=0\n",
      "[1530] Metric: \"progress percent\"=1.5639374425023\n",
      "[1560] Metric: \"training loss\"=4.11944580078125\n",
      "[1560] Metric: \"learning rate\"=7.973014412756824e-06\n",
      "[1560] Metric: \"tokens seen\"=165669\n",
      "[1560] Metric: \"epoch\"=0\n",
      "[1560] Metric: \"progress percent\"=1.5946028825513645\n",
      "[1590] Metric: \"training loss\"=3.2224173545837402\n",
      "[1590] Metric: \"learning rate\"=8.126341613002148e-06\n",
      "[1590] Metric: \"tokens seen\"=168574\n",
      "[1590] Metric: \"epoch\"=0\n",
      "[1590] Metric: \"progress percent\"=1.6252683226004292\n",
      "[1600] Example (example): \"fumaciously\n",
      "\n",
      "Photos?\n",
      "To add a variety\n",
      "\n",
      "### Response:\n",
      "The class\n",
      "They would also do\n",
      "How the individuals are called “my class by its peculiar form.\"\n",
      "[1620] Metric: \"training loss\"=2.407113552093506\n",
      "[1620] Metric: \"learning rate\"=8.279668813247472e-06\n",
      "[1620] Metric: \"tokens seen\"=171772\n",
      "[1620] Metric: \"epoch\"=0\n",
      "[1620] Metric: \"progress percent\"=1.6559337626494939\n",
      "[1650] Metric: \"training loss\"=3.3270041942596436\n",
      "[1650] Metric: \"learning rate\"=8.432996013492794e-06\n",
      "[1650] Metric: \"tokens seen\"=174678\n",
      "[1650] Metric: \"epoch\"=0\n",
      "[1650] Metric: \"progress percent\"=1.6865992026985588\n",
      "[1680] Metric: \"training loss\"=4.152211666107178\n",
      "[1680] Metric: \"learning rate\"=8.586323213738118e-06\n",
      "[1680] Metric: \"tokens seen\"=177662\n",
      "[1680] Metric: \"epoch\"=0\n",
      "[1680] Metric: \"progress percent\"=1.7172646427476235\n",
      "[1710] Metric: \"training loss\"=3.382490873336792\n",
      "[1710] Metric: \"learning rate\"=8.739650413983442e-06\n",
      "[1710] Metric: \"tokens seen\"=180744\n",
      "[1710] Metric: \"epoch\"=0\n",
      "[1710] Metric: \"progress percent\"=1.7479300827966882\n",
      "[1740] Metric: \"training loss\"=2.951258420944214\n",
      "[1740] Metric: \"learning rate\"=8.892977614228764e-06\n",
      "[1740] Metric: \"tokens seen\"=184172\n",
      "[1740] Metric: \"epoch\"=0\n",
      "[1740] Metric: \"progress percent\"=1.778595522845753\n",
      "[1770] Metric: \"training loss\"=2.481656312942505\n",
      "[1770] Metric: \"learning rate\"=9.046304814474088e-06\n",
      "[1770] Metric: \"tokens seen\"=186981\n",
      "[1770] Metric: \"epoch\"=0\n",
      "[1770] Metric: \"progress percent\"=1.8092609628948173\n",
      "[1800] Metric: \"training loss\"=4.661086082458496\n",
      "[1800] Metric: \"learning rate\"=9.199632014719412e-06\n",
      "[1800] Metric: \"tokens seen\"=189645\n",
      "[1800] Metric: \"epoch\"=0\n",
      "[1800] Metric: \"progress percent\"=1.8399264029438822\n",
      "[1800] Example (example): \"There is time that makes money\n",
      "\n",
      "### Response: Then, be sure the woman won't care for buying her husband\n",
      "\n",
      "### Response:\n",
      "I'm satisfied she don't care about her husband? ecosystem encoding: he's glad that she can help being good for the girl. websites: you's kind of you are her father and your wife, aren't they?### encoding: she'll turn your brain with you and she can stop talking about her daughter.###://ah?htm -\"o00�) Anyhow: I shall go about caring for children! Input! Hello, I don't want that. Please don\"\n",
      "[1800] Metric: \"validation loss\"=3.267706913106582\n",
      "[1830] Metric: \"training loss\"=4.69036340713501\n",
      "[1830] Metric: \"learning rate\"=9.352959214964736e-06\n",
      "[1830] Metric: \"tokens seen\"=193152\n",
      "[1830] Metric: \"epoch\"=0\n",
      "[1830] Metric: \"progress percent\"=1.870591842992947\n",
      "[1860] Metric: \"training loss\"=4.138864517211914\n",
      "[1860] Metric: \"learning rate\"=9.506286415210058e-06\n",
      "[1860] Metric: \"tokens seen\"=195690\n",
      "[1860] Metric: \"epoch\"=0\n",
      "[1860] Metric: \"progress percent\"=1.9012572830420116\n",
      "[1890] Metric: \"training loss\"=3.7713775634765625\n",
      "[1890] Metric: \"learning rate\"=9.659613615455382e-06\n",
      "[1890] Metric: \"tokens seen\"=198493\n",
      "[1890] Metric: \"epoch\"=0\n",
      "[1890] Metric: \"progress percent\"=1.9319227230910765\n",
      "[1920] Metric: \"training loss\"=1.5218013525009155\n",
      "[1920] Metric: \"learning rate\"=9.812940815700705e-06\n",
      "[1920] Metric: \"tokens seen\"=201651\n",
      "[1920] Metric: \"epoch\"=0\n",
      "[1920] Metric: \"progress percent\"=1.9625881631401412\n",
      "[1950] Metric: \"training loss\"=3.945619583129883\n",
      "[1950] Metric: \"learning rate\"=9.96626801594603e-06\n",
      "[1950] Metric: \"tokens seen\"=205008\n",
      "[1950] Metric: \"epoch\"=0\n",
      "[1950] Metric: \"progress percent\"=1.9932536031892059\n",
      "[1980] Metric: \"training loss\"=3.6158764362335205\n",
      "[1980] Metric: \"learning rate\"=1.0119595216191353e-05\n",
      "[1980] Metric: \"tokens seen\"=208269\n",
      "[1980] Metric: \"epoch\"=0\n",
      "[1980] Metric: \"progress percent\"=2.02391904323827\n",
      "[2000] Example (example): \"The name of an interpreter is 'I take care of those things on,' so it is usually spelled 'they shall know.'\n",
      "\n",
      "### Response:\n",
      "Fecilistic writing\n",
      "It is a message or something definite enough to help to produce them and produce new material into small groups with the definite intelligence that is needed and of elementary material objects and a sense can easily be used, and thus, what is possible under material and actual care, all these problems is given. When we come to consider a group of classes, we form our own workers, as the same people do. This is our present equipment. It has shown and recognized\"\n",
      "[2010] Metric: \"training loss\"=2.660250663757324\n",
      "[2010] Metric: \"learning rate\"=1.0272922416436677e-05\n",
      "[2010] Metric: \"tokens seen\"=211155\n",
      "[2010] Metric: \"epoch\"=0\n",
      "[2010] Metric: \"progress percent\"=2.0545844832873352\n",
      "[2040] Metric: \"training loss\"=3.318162441253662\n",
      "[2040] Metric: \"learning rate\"=1.0426249616682001e-05\n",
      "[2040] Metric: \"tokens seen\"=214371\n",
      "[2040] Metric: \"epoch\"=0\n",
      "[2040] Metric: \"progress percent\"=2.0852499233364\n",
      "[2070] Metric: \"training loss\"=2.039487600326538\n",
      "[2070] Metric: \"learning rate\"=1.0579576816927323e-05\n",
      "[2070] Metric: \"tokens seen\"=217391\n",
      "[2070] Metric: \"epoch\"=0\n",
      "[2070] Metric: \"progress percent\"=2.1159153633854646\n",
      "[2100] Metric: \"training loss\"=1.8558368682861328\n",
      "[2100] Metric: \"learning rate\"=1.0732904017172647e-05\n",
      "[2100] Metric: \"tokens seen\"=220404\n",
      "[2100] Metric: \"epoch\"=0\n",
      "[2100] Metric: \"progress percent\"=2.1465808034345293\n",
      "[2130] Metric: \"training loss\"=3.5185060501098633\n",
      "[2130] Metric: \"learning rate\"=1.0886231217417971e-05\n",
      "[2130] Metric: \"tokens seen\"=223981\n",
      "[2130] Metric: \"epoch\"=0\n",
      "[2130] Metric: \"progress percent\"=2.177246243483594\n",
      "[2160] Metric: \"training loss\"=2.253369092941284\n",
      "[2160] Metric: \"learning rate\"=1.1039558417663293e-05\n",
      "[2160] Metric: \"tokens seen\"=226961\n",
      "[2160] Metric: \"epoch\"=0\n",
      "[2160] Metric: \"progress percent\"=2.2079116835326587\n",
      "[2190] Metric: \"training loss\"=2.3030924797058105\n",
      "[2190] Metric: \"learning rate\"=1.1192885617908617e-05\n",
      "[2190] Metric: \"tokens seen\"=230506\n",
      "[2190] Metric: \"epoch\"=0\n",
      "[2190] Metric: \"progress percent\"=2.2385771235817233\n",
      "[2200] Example (example): \"They read the title word at the page of time they studied the sentence the text they called, so on.\"\n",
      "[2220] Metric: \"training loss\"=3.9840457439422607\n",
      "[2220] Metric: \"learning rate\"=1.1346212818153941e-05\n",
      "[2220] Metric: \"tokens seen\"=233567\n",
      "[2220] Metric: \"epoch\"=0\n",
      "[2220] Metric: \"progress percent\"=2.269242563630788\n",
      "[2250] Metric: \"training loss\"=2.376305103302002\n",
      "[2250] Metric: \"learning rate\"=1.1499540018399265e-05\n",
      "[2250] Metric: \"tokens seen\"=236801\n",
      "[2250] Metric: \"epoch\"=0\n",
      "[2250] Metric: \"progress percent\"=2.2999080036798527\n",
      "[2280] Metric: \"training loss\"=3.6981308460235596\n",
      "[2280] Metric: \"learning rate\"=1.1652867218644587e-05\n",
      "[2280] Metric: \"tokens seen\"=239999\n",
      "[2280] Metric: \"epoch\"=0\n",
      "[2280] Metric: \"progress percent\"=2.3305734437289174\n",
      "[2310] Metric: \"training loss\"=2.739339828491211\n",
      "[2310] Metric: \"learning rate\"=1.1806194418889911e-05\n",
      "[2310] Metric: \"tokens seen\"=243278\n",
      "[2310] Metric: \"epoch\"=0\n",
      "[2310] Metric: \"progress percent\"=2.361238883777982\n",
      "[2340] Metric: \"training loss\"=2.4209916591644287\n",
      "[2340] Metric: \"learning rate\"=1.1959521619135235e-05\n",
      "[2340] Metric: \"tokens seen\"=246235\n",
      "[2340] Metric: \"epoch\"=0\n",
      "[2340] Metric: \"progress percent\"=2.391904323827047\n",
      "[2370] Metric: \"training loss\"=2.838107109069824\n",
      "[2370] Metric: \"learning rate\"=1.2112848819380559e-05\n",
      "[2370] Metric: \"tokens seen\"=249358\n",
      "[2370] Metric: \"epoch\"=0\n",
      "[2370] Metric: \"progress percent\"=2.422569763876112\n",
      "[2400] Metric: \"training loss\"=3.016649007797241\n",
      "[2400] Metric: \"learning rate\"=1.2266176019625881e-05\n",
      "[2400] Metric: \"tokens seen\"=252057\n",
      "[2400] Metric: \"epoch\"=0\n",
      "[2400] Metric: \"progress percent\"=2.453235203925176\n",
      "[2400] Example (example): \"Zirping\n",
      "\n",
      " GDP:\n",
      "Depid\n",
      "Filled\n",
      "\n",
      "Frown and [Lipp].### Response:\n",
      "Mild as [Rough] [Wreck] [Cattle] [Told].\"\n",
      "[2400] Metric: \"validation loss\"=3.1622883993036606\n",
      "[2430] Metric: \"training loss\"=3.4561569690704346\n",
      "[2430] Metric: \"learning rate\"=1.2419503219871207e-05\n",
      "[2430] Metric: \"tokens seen\"=254880\n",
      "[2430] Metric: \"epoch\"=0\n",
      "[2430] Metric: \"progress percent\"=2.483900643974241\n",
      "[2460] Metric: \"training loss\"=3.900709390640259\n",
      "[2460] Metric: \"learning rate\"=1.257283042011653e-05\n",
      "[2460] Metric: \"tokens seen\"=257909\n",
      "[2460] Metric: \"epoch\"=0\n",
      "[2460] Metric: \"progress percent\"=2.5145660840233055\n",
      "[2490] Metric: \"training loss\"=3.7266459465026855\n",
      "[2490] Metric: \"learning rate\"=1.2726157620361853e-05\n",
      "[2490] Metric: \"tokens seen\"=260853\n",
      "[2490] Metric: \"epoch\"=0\n",
      "[2490] Metric: \"progress percent\"=2.5452315240723706\n",
      "[2520] Metric: \"training loss\"=4.2401885986328125\n",
      "[2520] Metric: \"learning rate\"=1.2879484820607177e-05\n",
      "[2520] Metric: \"tokens seen\"=263603\n",
      "[2520] Metric: \"epoch\"=0\n",
      "[2520] Metric: \"progress percent\"=2.5758969641214353\n",
      "[2550] Metric: \"training loss\"=2.9848055839538574\n",
      "[2550] Metric: \"learning rate\"=1.30328120208525e-05\n",
      "[2550] Metric: \"tokens seen\"=267243\n",
      "[2550] Metric: \"epoch\"=0\n",
      "[2550] Metric: \"progress percent\"=2.6065624041705\n",
      "[2580] Metric: \"training loss\"=3.009105682373047\n",
      "[2580] Metric: \"learning rate\"=1.3186139221097823e-05\n",
      "[2580] Metric: \"tokens seen\"=270779\n",
      "[2580] Metric: \"epoch\"=0\n",
      "[2580] Metric: \"progress percent\"=2.6372278442195647\n",
      "[2600] Example (example): \"The author wrote a poem for that of that great poem and poem. This poem gives two directions.\n",
      "\n",
      "Create with the sentence.\n",
      "\n",
      " ecosystem topics: a phrase which is to teach people about things which are to come on their way to life. Input a sentence expressing the pleasure of talking about things and the happiness of living in life makes him feel that those days are always given, to study, and learn about other things the love they need, even then for a happier day through their experiences that have been a time at present in heaven.\n",
      "\n",
      " Microsoft a story against a novel?\n",
      "\n",
      "### Response:\n",
      "The poet refers\"\n",
      "[2610] Metric: \"training loss\"=2.6265032291412354\n",
      "[2610] Metric: \"learning rate\"=1.3339466421343147e-05\n",
      "[2610] Metric: \"tokens seen\"=273932\n",
      "[2610] Metric: \"epoch\"=0\n",
      "[2610] Metric: \"progress percent\"=2.667893284268629\n",
      "[2640] Metric: \"training loss\"=3.8724820613861084\n",
      "[2640] Metric: \"learning rate\"=1.349279362158847e-05\n",
      "[2640] Metric: \"tokens seen\"=277572\n",
      "[2640] Metric: \"epoch\"=0\n",
      "[2640] Metric: \"progress percent\"=2.698558724317694\n",
      "[2670] Metric: \"training loss\"=4.327874660491943\n",
      "[2670] Metric: \"learning rate\"=1.3646120821833794e-05\n",
      "[2670] Metric: \"tokens seen\"=280937\n",
      "[2670] Metric: \"epoch\"=0\n",
      "[2670] Metric: \"progress percent\"=2.7292241643667587\n",
      "[2700] Metric: \"training loss\"=1.8090457916259766\n",
      "[2700] Metric: \"learning rate\"=1.3799448022079117e-05\n",
      "[2700] Metric: \"tokens seen\"=284168\n",
      "[2700] Metric: \"epoch\"=0\n",
      "[2700] Metric: \"progress percent\"=2.7598896044158234\n",
      "[2730] Metric: \"training loss\"=3.748789072036743\n",
      "[2730] Metric: \"learning rate\"=1.395277522232444e-05\n",
      "[2730] Metric: \"tokens seen\"=287069\n",
      "[2730] Metric: \"epoch\"=0\n",
      "[2730] Metric: \"progress percent\"=2.790555044464888\n",
      "[2760] Metric: \"training loss\"=4.016653537750244\n",
      "[2760] Metric: \"learning rate\"=1.4106102422569764e-05\n",
      "[2760] Metric: \"tokens seen\"=290104\n",
      "[2760] Metric: \"epoch\"=0\n",
      "[2760] Metric: \"progress percent\"=2.821220484513953\n",
      "[2790] Metric: \"training loss\"=3.637939453125\n",
      "[2790] Metric: \"learning rate\"=1.4259429622815088e-05\n",
      "[2790] Metric: \"tokens seen\"=293213\n",
      "[2790] Metric: \"epoch\"=0\n",
      "[2790] Metric: \"progress percent\"=2.8518859245630175\n",
      "[2800] Example (example): \"vapen It's difficult to find in this passage that puts a better idea into action.\n",
      "\n",
      "### Response:\n",
      "Unchange what is it that brings all your chances to achieve this result?\"\n",
      "[2820] Metric: \"training loss\"=3.427588701248169\n",
      "[2820] Metric: \"learning rate\"=1.441275682306041e-05\n",
      "[2820] Metric: \"tokens seen\"=296192\n",
      "[2820] Metric: \"epoch\"=0\n",
      "[2820] Metric: \"progress percent\"=2.882551364612082\n",
      "[2850] Metric: \"training loss\"=2.7779321670532227\n",
      "[2850] Metric: \"learning rate\"=1.4566084023305734e-05\n",
      "[2850] Metric: \"tokens seen\"=298870\n",
      "[2850] Metric: \"epoch\"=0\n",
      "[2850] Metric: \"progress percent\"=2.913216804661147\n",
      "[2880] Metric: \"training loss\"=2.724285364151001\n",
      "[2880] Metric: \"learning rate\"=1.4719411223551058e-05\n",
      "[2880] Metric: \"tokens seen\"=302124\n",
      "[2880] Metric: \"epoch\"=0\n",
      "[2880] Metric: \"progress percent\"=2.9438822447102115\n",
      "[2910] Metric: \"training loss\"=3.1535420417785645\n",
      "[2910] Metric: \"learning rate\"=1.487273842379638e-05\n",
      "[2910] Metric: \"tokens seen\"=305072\n",
      "[2910] Metric: \"epoch\"=0\n",
      "[2910] Metric: \"progress percent\"=2.9745476847592762\n",
      "[2940] Metric: \"training loss\"=1.6784272193908691\n",
      "[2940] Metric: \"learning rate\"=1.5026065624041704e-05\n",
      "[2940] Metric: \"tokens seen\"=308678\n",
      "[2940] Metric: \"epoch\"=0\n",
      "[2940] Metric: \"progress percent\"=3.005213124808341\n",
      "[2970] Metric: \"training loss\"=3.3427367210388184\n",
      "[2970] Metric: \"learning rate\"=1.5179392824287028e-05\n",
      "[2970] Metric: \"tokens seen\"=312535\n",
      "[2970] Metric: \"epoch\"=0\n",
      "[2970] Metric: \"progress percent\"=3.035878564857406\n",
      "[3000] Metric: \"training loss\"=1.84181547164917\n",
      "[3000] Metric: \"learning rate\"=1.5332720024532352e-05\n",
      "[3000] Metric: \"tokens seen\"=315401\n",
      "[3000] Metric: \"epoch\"=0\n",
      "[3000] Metric: \"progress percent\"=3.0665440049064703\n",
      "[3000] Example (example): \"The words should be used: 'bitter are good.' She often goes by with a key-hole than is her habit.\" Its contents are made known, it is good for a girl to remove, or a good morning's night! Finally, a week is just a lovely spring.\n",
      "The flowers must never do the same: her way will fade and there is often something to help remove\n",
      "The apples can't hurt her. There is the sweet grass as easy as this.\"\n",
      "[3000] Metric: \"validation loss\"=3.0662883087700488\n",
      "[3030] Metric: \"training loss\"=2.14276123046875\n",
      "[3030] Metric: \"learning rate\"=1.5486047224777674e-05\n",
      "[3030] Metric: \"tokens seen\"=318854\n",
      "[3030] Metric: \"epoch\"=0\n",
      "[3030] Metric: \"progress percent\"=3.097209444955535\n",
      "[3060] Metric: \"training loss\"=2.925739049911499\n",
      "[3060] Metric: \"learning rate\"=1.5639374425023e-05\n",
      "[3060] Metric: \"tokens seen\"=322136\n",
      "[3060] Metric: \"epoch\"=0\n",
      "[3060] Metric: \"progress percent\"=3.1278748850046\n",
      "[3090] Metric: \"training loss\"=3.2034454345703125\n",
      "[3090] Metric: \"learning rate\"=1.5792701625268326e-05\n",
      "[3090] Metric: \"tokens seen\"=325641\n",
      "[3090] Metric: \"epoch\"=0\n",
      "[3090] Metric: \"progress percent\"=3.1585403250536643\n",
      "[3120] Metric: \"training loss\"=2.2000205516815186\n",
      "[3120] Metric: \"learning rate\"=1.5946028825513648e-05\n",
      "[3120] Metric: \"tokens seen\"=328466\n",
      "[3120] Metric: \"epoch\"=0\n",
      "[3120] Metric: \"progress percent\"=3.189205765102729\n",
      "[3150] Metric: \"training loss\"=2.040142774581909\n",
      "[3150] Metric: \"learning rate\"=1.609935602575897e-05\n",
      "[3150] Metric: \"tokens seen\"=331544\n",
      "[3150] Metric: \"epoch\"=0\n",
      "[3150] Metric: \"progress percent\"=3.219871205151794\n",
      "[3180] Metric: \"training loss\"=2.510430097579956\n",
      "[3180] Metric: \"learning rate\"=1.6252683226004295e-05\n",
      "[3180] Metric: \"tokens seen\"=334839\n",
      "[3180] Metric: \"epoch\"=0\n",
      "[3180] Metric: \"progress percent\"=3.2505366452008584\n",
      "[3200] Example (example): \"A paragraph expresses that these words, \"mortal\", (\"mursed\" (\"mamed\" (\"mainted!\" (\"mound\")\n",
      "marched:\n",
      "\"Why's it\" (\"mursedness\")\n",
      "blushing:\n",
      "\"Because he has always a mind.\"### global:\n",
      "\"'Polly-mo!\"\".### Response:\n",
      "\n",
      "blushing]\n",
      "blushing) continues: \"Ohy!\" etc. Next note of comma as the opposite of \"thick\".\"\n",
      "[3210] Metric: \"training loss\"=1.8552911281585693\n",
      "[3210] Metric: \"learning rate\"=1.6406010426249618e-05\n",
      "[3210] Metric: \"tokens seen\"=337878\n",
      "[3210] Metric: \"epoch\"=0\n",
      "[3210] Metric: \"progress percent\"=3.2812020852499235\n",
      "[3240] Metric: \"training loss\"=2.529752492904663\n",
      "[3240] Metric: \"learning rate\"=1.6559337626494943e-05\n",
      "[3240] Metric: \"tokens seen\"=341065\n",
      "[3240] Metric: \"epoch\"=0\n",
      "[3240] Metric: \"progress percent\"=3.3118675252989878\n",
      "[3270] Metric: \"training loss\"=2.903718948364258\n",
      "[3270] Metric: \"learning rate\"=1.6712664826740265e-05\n",
      "[3270] Metric: \"tokens seen\"=344631\n",
      "[3270] Metric: \"epoch\"=0\n",
      "[3270] Metric: \"progress percent\"=3.342532965348053\n",
      "[3300] Metric: \"training loss\"=1.7530789375305176\n",
      "[3300] Metric: \"learning rate\"=1.6865992026985588e-05\n",
      "[3300] Metric: \"tokens seen\"=347509\n",
      "[3300] Metric: \"epoch\"=0\n",
      "[3300] Metric: \"progress percent\"=3.3731984053971176\n",
      "[3330] Metric: \"training loss\"=3.9648852348327637\n",
      "[3330] Metric: \"learning rate\"=1.7019319227230913e-05\n",
      "[3330] Metric: \"tokens seen\"=350978\n",
      "[3330] Metric: \"epoch\"=0\n",
      "[3330] Metric: \"progress percent\"=3.403863845446182\n",
      "[3360] Metric: \"training loss\"=3.215266704559326\n",
      "[3360] Metric: \"learning rate\"=1.7172646427476235e-05\n",
      "[3360] Metric: \"tokens seen\"=353721\n",
      "[3360] Metric: \"epoch\"=0\n",
      "[3360] Metric: \"progress percent\"=3.434529285495247\n",
      "[3390] Metric: \"training loss\"=3.0299830436706543\n",
      "[3390] Metric: \"learning rate\"=1.7325973627721558e-05\n",
      "[3390] Metric: \"tokens seen\"=356662\n",
      "[3390] Metric: \"epoch\"=0\n",
      "[3390] Metric: \"progress percent\"=3.465194725544311\n",
      "[3400] Example (example): \"The cat is the cat is the mouse, and it soon rises out of its mind.\"\n",
      "[3420] Metric: \"training loss\"=4.1366963386535645\n",
      "[3420] Metric: \"learning rate\"=1.7479300827966883e-05\n",
      "[3420] Metric: \"tokens seen\"=360366\n",
      "[3420] Metric: \"epoch\"=0\n",
      "[3420] Metric: \"progress percent\"=3.4958601655933763\n",
      "[3450] Metric: \"training loss\"=1.7340381145477295\n",
      "[3450] Metric: \"learning rate\"=1.7632628028212205e-05\n",
      "[3450] Metric: \"tokens seen\"=363578\n",
      "[3450] Metric: \"epoch\"=0\n",
      "[3450] Metric: \"progress percent\"=3.526525605642441\n",
      "[3480] Metric: \"training loss\"=4.090480804443359\n",
      "[3480] Metric: \"learning rate\"=1.7785955228457528e-05\n",
      "[3480] Metric: \"tokens seen\"=367137\n",
      "[3480] Metric: \"epoch\"=0\n",
      "[3480] Metric: \"progress percent\"=3.557191045691506\n",
      "[3510] Metric: \"training loss\"=2.5584418773651123\n",
      "[3510] Metric: \"learning rate\"=1.7939282428702853e-05\n",
      "[3510] Metric: \"tokens seen\"=370179\n",
      "[3510] Metric: \"epoch\"=0\n",
      "[3510] Metric: \"progress percent\"=3.5878564857405704\n",
      "[3540] Metric: \"training loss\"=2.011892318725586\n",
      "[3540] Metric: \"learning rate\"=1.8092609628948175e-05\n",
      "[3540] Metric: \"tokens seen\"=372975\n",
      "[3540] Metric: \"epoch\"=0\n",
      "[3540] Metric: \"progress percent\"=3.6185219257896346\n",
      "[3570] Metric: \"training loss\"=4.074613571166992\n",
      "[3570] Metric: \"learning rate\"=1.82459368291935e-05\n",
      "[3570] Metric: \"tokens seen\"=376198\n",
      "[3570] Metric: \"epoch\"=0\n",
      "[3570] Metric: \"progress percent\"=3.6491873658386997\n",
      "[3600] Metric: \"training loss\"=1.3081457614898682\n",
      "[3600] Metric: \"learning rate\"=1.8399264029438823e-05\n",
      "[3600] Metric: \"tokens seen\"=379022\n",
      "[3600] Metric: \"epoch\"=0\n",
      "[3600] Metric: \"progress percent\"=3.6798528058877644\n",
      "[3600] Example (example): \"fustifier (uping)\n",
      "Fictner-hamp\n",
      "Fict.  \n",
      "Fetcher \n",
      "Fictter c.  The cat-fighting card is\n",
      "Fliester leak (\"Firing\"]. To \"favor\") To \"swallow,\" to \"carp\"\n",
      "Carpetteus, \n",
      "Athmer \n",
      "Deterrot (omptive)\n",
      "Rictatori\n",
      "Fiscus Athmer, \n",
      "Kalketteus Attich, \n",
      "Gorgens Comple\n",
      "Giscus Reindling\n",
      "Fecters T\"\n",
      "[3600] Metric: \"validation loss\"=2.9980641732028888\n",
      "[3630] Metric: \"training loss\"=1.83909273147583\n",
      "[3630] Metric: \"learning rate\"=1.8552591229684145e-05\n",
      "[3630] Metric: \"tokens seen\"=381776\n",
      "[3630] Metric: \"epoch\"=0\n",
      "[3630] Metric: \"progress percent\"=3.7105182459368296\n",
      "[3660] Metric: \"training loss\"=1.7396838665008545\n",
      "[3660] Metric: \"learning rate\"=1.870591842992947e-05\n",
      "[3660] Metric: \"tokens seen\"=384653\n",
      "[3660] Metric: \"epoch\"=0\n",
      "[3660] Metric: \"progress percent\"=3.741183685985894\n",
      "[3690] Metric: \"training loss\"=3.7986748218536377\n",
      "[3690] Metric: \"learning rate\"=1.8859245630174793e-05\n",
      "[3690] Metric: \"tokens seen\"=387940\n",
      "[3690] Metric: \"epoch\"=0\n",
      "[3690] Metric: \"progress percent\"=3.771849126034959\n",
      "[3720] Metric: \"training loss\"=2.1387977600097656\n",
      "[3720] Metric: \"learning rate\"=1.9012572830420115e-05\n",
      "[3720] Metric: \"tokens seen\"=390924\n",
      "[3720] Metric: \"epoch\"=0\n",
      "[3720] Metric: \"progress percent\"=3.802514566084023\n",
      "[3750] Metric: \"training loss\"=3.0608274936676025\n",
      "[3750] Metric: \"learning rate\"=1.916590003066544e-05\n",
      "[3750] Metric: \"tokens seen\"=394016\n",
      "[3750] Metric: \"epoch\"=0\n",
      "[3750] Metric: \"progress percent\"=3.833180006133088\n",
      "[3780] Metric: \"training loss\"=2.7360477447509766\n",
      "[3780] Metric: \"learning rate\"=1.9319227230910763e-05\n",
      "[3780] Metric: \"tokens seen\"=397018\n",
      "[3780] Metric: \"epoch\"=0\n",
      "[3780] Metric: \"progress percent\"=3.863845446182153\n",
      "[3800] Example (example): \"fluxified/fractions used in a phrase based on an appending sentence\"\n",
      "[3810] Metric: \"training loss\"=3.9429285526275635\n",
      "[3810] Metric: \"learning rate\"=1.9472554431156085e-05\n",
      "[3810] Metric: \"tokens seen\"=400299\n",
      "[3810] Metric: \"epoch\"=0\n",
      "[3810] Metric: \"progress percent\"=3.894510886231217\n",
      "[3840] Metric: \"training loss\"=2.6125829219818115\n",
      "[3840] Metric: \"learning rate\"=1.962588163140141e-05\n",
      "[3840] Metric: \"tokens seen\"=403730\n",
      "[3840] Metric: \"epoch\"=0\n",
      "[3840] Metric: \"progress percent\"=3.9251763262802823\n",
      "[3870] Metric: \"training loss\"=2.288778305053711\n",
      "[3870] Metric: \"learning rate\"=1.9779208831646733e-05\n",
      "[3870] Metric: \"tokens seen\"=407031\n",
      "[3870] Metric: \"epoch\"=0\n",
      "[3870] Metric: \"progress percent\"=3.9558417663293466\n",
      "[3900] Metric: \"training loss\"=2.6721384525299072\n",
      "[3900] Metric: \"learning rate\"=1.993253603189206e-05\n",
      "[3900] Metric: \"tokens seen\"=410292\n",
      "[3900] Metric: \"epoch\"=0\n",
      "[3900] Metric: \"progress percent\"=3.9865072063784117\n",
      "[3930] Metric: \"training loss\"=3.460019826889038\n",
      "[3930] Metric: \"learning rate\"=2.008586323213738e-05\n",
      "[3930] Metric: \"tokens seen\"=413496\n",
      "[3930] Metric: \"epoch\"=0\n",
      "[3930] Metric: \"progress percent\"=4.017172646427476\n",
      "[3960] Metric: \"training loss\"=3.9521148204803467\n",
      "[3960] Metric: \"learning rate\"=2.0239190432382707e-05\n",
      "[3960] Metric: \"tokens seen\"=416860\n",
      "[3960] Metric: \"epoch\"=0\n",
      "[3960] Metric: \"progress percent\"=4.04783808647654\n",
      "[3990] Metric: \"training loss\"=1.928792119026184\n",
      "[3990] Metric: \"learning rate\"=2.039251763262803e-05\n",
      "[3990] Metric: \"tokens seen\"=419960\n",
      "[3990] Metric: \"epoch\"=0\n",
      "[3990] Metric: \"progress percent\"=4.078503526525606\n",
      "[4000] Example (example): \"a^a],  \n",
      "  \n",
      "       n2 cm.\"\n",
      "[4020] Metric: \"training loss\"=2.2758913040161133\n",
      "[4020] Metric: \"learning rate\"=2.0545844832873354e-05\n",
      "[4020] Metric: \"tokens seen\"=423403\n",
      "[4020] Metric: \"epoch\"=0\n",
      "[4020] Metric: \"progress percent\"=4.1091689665746705\n",
      "[4050] Metric: \"training loss\"=2.240170478820801\n",
      "[4050] Metric: \"learning rate\"=2.0699172033118677e-05\n",
      "[4050] Metric: \"tokens seen\"=426929\n",
      "[4050] Metric: \"epoch\"=0\n",
      "[4050] Metric: \"progress percent\"=4.139834406623735\n",
      "[4080] Metric: \"training loss\"=2.3633341789245605\n",
      "[4080] Metric: \"learning rate\"=2.0852499233364002e-05\n",
      "[4080] Metric: \"tokens seen\"=430233\n",
      "[4080] Metric: \"epoch\"=0\n",
      "[4080] Metric: \"progress percent\"=4.1704998466728\n",
      "[4110] Metric: \"training loss\"=2.7574188709259033\n",
      "[4110] Metric: \"learning rate\"=2.1005826433609324e-05\n",
      "[4110] Metric: \"tokens seen\"=433480\n",
      "[4110] Metric: \"epoch\"=0\n",
      "[4110] Metric: \"progress percent\"=4.2011652867218645\n",
      "[4140] Metric: \"training loss\"=2.092878818511963\n",
      "[4140] Metric: \"learning rate\"=2.1159153633854647e-05\n",
      "[4140] Metric: \"tokens seen\"=436701\n",
      "[4140] Metric: \"epoch\"=0\n",
      "[4140] Metric: \"progress percent\"=4.231830726770929\n",
      "[4170] Metric: \"training loss\"=2.874173641204834\n",
      "[4170] Metric: \"learning rate\"=2.1312480834099972e-05\n",
      "[4170] Metric: \"tokens seen\"=439923\n",
      "[4170] Metric: \"epoch\"=0\n",
      "[4170] Metric: \"progress percent\"=4.262496166819994\n",
      "[4200] Metric: \"training loss\"=4.132619380950928\n",
      "[4200] Metric: \"learning rate\"=2.1465808034345294e-05\n",
      "[4200] Metric: \"tokens seen\"=442826\n",
      "[4200] Metric: \"epoch\"=0\n",
      "[4200] Metric: \"progress percent\"=4.293161606869059\n",
      "[4200] Example (example): \"The person is a high-headed dog, with broad legs; is often in the stable when he can keep his eyes up and his face around. Next come into sight. There is an example that will be his habit of speech after a night to see friends all around with their arms about his neck, and that is his turn. \n",
      "The person is able to stop at that position, but by the moment I open the door and speak to him before she begins to talk, there we could meet before the day I saw the eyes of these great children, great souls. However little he looks wept he knows he and then is\"\n",
      "[4200] Metric: \"validation loss\"=2.9346658891322566\n",
      "[4230] Metric: \"training loss\"=3.2253835201263428\n",
      "[4230] Metric: \"learning rate\"=2.1619135234590617e-05\n",
      "[4230] Metric: \"tokens seen\"=446193\n",
      "[4230] Metric: \"epoch\"=0\n",
      "[4230] Metric: \"progress percent\"=4.323827046918123\n",
      "[4260] Metric: \"training loss\"=2.503443717956543\n",
      "[4260] Metric: \"learning rate\"=2.1772462434835942e-05\n",
      "[4260] Metric: \"tokens seen\"=449043\n",
      "[4260] Metric: \"epoch\"=0\n",
      "[4260] Metric: \"progress percent\"=4.354492486967188\n",
      "[4290] Metric: \"training loss\"=3.9006330966949463\n",
      "[4290] Metric: \"learning rate\"=2.1925789635081264e-05\n",
      "[4290] Metric: \"tokens seen\"=452089\n",
      "[4290] Metric: \"epoch\"=0\n",
      "[4290] Metric: \"progress percent\"=4.385157927016253\n",
      "[4320] Metric: \"training loss\"=2.847759485244751\n",
      "[4320] Metric: \"learning rate\"=2.2079116835326587e-05\n",
      "[4320] Metric: \"tokens seen\"=455244\n",
      "[4320] Metric: \"epoch\"=0\n",
      "[4320] Metric: \"progress percent\"=4.415823367065317\n",
      "[4350] Metric: \"training loss\"=2.787379741668701\n",
      "[4350] Metric: \"learning rate\"=2.2232444035571912e-05\n",
      "[4350] Metric: \"tokens seen\"=457925\n",
      "[4350] Metric: \"epoch\"=0\n",
      "[4350] Metric: \"progress percent\"=4.446488807114382\n",
      "[4380] Metric: \"training loss\"=3.3745219707489014\n",
      "[4380] Metric: \"learning rate\"=2.2385771235817234e-05\n",
      "[4380] Metric: \"tokens seen\"=461164\n",
      "[4380] Metric: \"epoch\"=0\n",
      "[4380] Metric: \"progress percent\"=4.477154247163447\n",
      "[4400] Example (example): \"It is easy to make it less rapid. This will prevent it becoming easier for me, but not also in a long walk.\"\n",
      "[4410] Metric: \"training loss\"=1.4769362211227417\n",
      "[4410] Metric: \"learning rate\"=2.253909843606256e-05\n",
      "[4410] Metric: \"tokens seen\"=464423\n",
      "[4410] Metric: \"epoch\"=0\n",
      "[4410] Metric: \"progress percent\"=4.507819687212511\n",
      "[4440] Metric: \"training loss\"=2.695621967315674\n",
      "[4440] Metric: \"learning rate\"=2.2692425636307882e-05\n",
      "[4440] Metric: \"tokens seen\"=467605\n",
      "[4440] Metric: \"epoch\"=0\n",
      "[4440] Metric: \"progress percent\"=4.538485127261576\n",
      "[4470] Metric: \"training loss\"=2.8542110919952393\n",
      "[4470] Metric: \"learning rate\"=2.2845752836553204e-05\n",
      "[4470] Metric: \"tokens seen\"=470758\n",
      "[4470] Metric: \"epoch\"=0\n",
      "[4470] Metric: \"progress percent\"=4.569150567310641\n",
      "[4500] Metric: \"training loss\"=3.553539752960205\n",
      "[4500] Metric: \"learning rate\"=2.299908003679853e-05\n",
      "[4500] Metric: \"tokens seen\"=474262\n",
      "[4500] Metric: \"epoch\"=0\n",
      "[4500] Metric: \"progress percent\"=4.599816007359705\n",
      "[4530] Metric: \"training loss\"=3.7754764556884766\n",
      "[4530] Metric: \"learning rate\"=2.3152407237043852e-05\n",
      "[4530] Metric: \"tokens seen\"=477473\n",
      "[4530] Metric: \"epoch\"=0\n",
      "[4530] Metric: \"progress percent\"=4.630481447408771\n",
      "[4560] Metric: \"training loss\"=2.5075690746307373\n",
      "[4560] Metric: \"learning rate\"=2.3305734437289174e-05\n",
      "[4560] Metric: \"tokens seen\"=480474\n",
      "[4560] Metric: \"epoch\"=0\n",
      "[4560] Metric: \"progress percent\"=4.661146887457835\n",
      "[4590] Metric: \"training loss\"=3.8751957416534424\n",
      "[4590] Metric: \"learning rate\"=2.34590616375345e-05\n",
      "[4590] Metric: \"tokens seen\"=483935\n",
      "[4590] Metric: \"epoch\"=0\n",
      "[4590] Metric: \"progress percent\"=4.6918123275068995\n",
      "[4600] Example (example): \"Focciterificatory letter\n",
      "The emotion is an emotion more intense. It is the impression being a sense of humor. It is an expression of beauty like beauty and harmony that it reflects; something about emotion is in expression more tranquil in reality. At any moment what emotion and passion of sentiment and reality are on one scale makes us love. The emotions may flow into us a shade and light us when it moves into self. A sense of beauty which we know well are as powerful and which we can touch all within the inner and primary objects.\"\n",
      "[4620] Metric: \"training loss\"=2.85229229927063\n",
      "[4620] Metric: \"learning rate\"=2.3612388837779822e-05\n",
      "[4620] Metric: \"tokens seen\"=487348\n",
      "[4620] Metric: \"epoch\"=0\n",
      "[4620] Metric: \"progress percent\"=4.722477767555964\n",
      "[4650] Metric: \"training loss\"=3.384697437286377\n",
      "[4650] Metric: \"learning rate\"=2.3765716038025144e-05\n",
      "[4650] Metric: \"tokens seen\"=490473\n",
      "[4650] Metric: \"epoch\"=0\n",
      "[4650] Metric: \"progress percent\"=4.753143207605029\n",
      "[4680] Metric: \"training loss\"=3.7155680656433105\n",
      "[4680] Metric: \"learning rate\"=2.391904323827047e-05\n",
      "[4680] Metric: \"tokens seen\"=493737\n",
      "[4680] Metric: \"epoch\"=0\n",
      "[4680] Metric: \"progress percent\"=4.783808647654094\n",
      "[4710] Metric: \"training loss\"=2.784634590148926\n",
      "[4710] Metric: \"learning rate\"=2.4072370438515792e-05\n",
      "[4710] Metric: \"tokens seen\"=496988\n",
      "[4710] Metric: \"epoch\"=0\n",
      "[4710] Metric: \"progress percent\"=4.814474087703158\n",
      "[4740] Metric: \"training loss\"=3.090756893157959\n",
      "[4740] Metric: \"learning rate\"=2.4225697638761118e-05\n",
      "[4740] Metric: \"tokens seen\"=499720\n",
      "[4740] Metric: \"epoch\"=0\n",
      "[4740] Metric: \"progress percent\"=4.845139527752224\n",
      "[4770] Metric: \"training loss\"=2.3756468296051025\n",
      "[4770] Metric: \"learning rate\"=2.437902483900644e-05\n",
      "[4770] Metric: \"tokens seen\"=503201\n",
      "[4770] Metric: \"epoch\"=0\n",
      "[4770] Metric: \"progress percent\"=4.875804967801288\n",
      "[4800] Metric: \"training loss\"=3.8860630989074707\n",
      "[4800] Metric: \"learning rate\"=2.4532352039251762e-05\n",
      "[4800] Metric: \"tokens seen\"=506055\n",
      "[4800] Metric: \"epoch\"=0\n",
      "[4800] Metric: \"progress percent\"=4.906470407850352\n",
      "[4800] Example (example): \"Movable Your letter\n",
      "I would make bold\n",
      "VIII LOVE\n",
      "This should prove such as \"good or false\" \n",
      "The use would not keep us in wait. But that doesn't lead to serious conversation. We should be able by our experience that these thoughts may come to a place to understand?\"\n",
      "[4800] Metric: \"validation loss\"=2.880271569186566\n",
      "[4830] Metric: \"training loss\"=1.7479169368743896\n",
      "[4830] Metric: \"learning rate\"=2.4685679239497088e-05\n",
      "[4830] Metric: \"tokens seen\"=509459\n",
      "[4830] Metric: \"epoch\"=0\n",
      "[4830] Metric: \"progress percent\"=4.937135847899418\n",
      "[4860] Metric: \"training loss\"=2.6081736087799072\n",
      "[4860] Metric: \"learning rate\"=2.4839006439742413e-05\n",
      "[4860] Metric: \"tokens seen\"=512512\n",
      "[4860] Metric: \"epoch\"=0\n",
      "[4860] Metric: \"progress percent\"=4.967801287948482\n",
      "[4890] Metric: \"training loss\"=2.843435525894165\n",
      "[4890] Metric: \"learning rate\"=2.4992333639987735e-05\n",
      "[4890] Metric: \"tokens seen\"=515460\n",
      "[4890] Metric: \"epoch\"=0\n",
      "[4890] Metric: \"progress percent\"=4.998466727997547\n",
      "[4920] Metric: \"training loss\"=3.8734219074249268\n",
      "[4920] Metric: \"learning rate\"=2.514566084023306e-05\n",
      "[4920] Metric: \"tokens seen\"=518920\n",
      "[4920] Metric: \"epoch\"=0\n",
      "[4920] Metric: \"progress percent\"=5.029132168046611\n",
      "[4950] Metric: \"training loss\"=2.8776721954345703\n",
      "[4950] Metric: \"learning rate\"=2.5298988040478383e-05\n",
      "[4950] Metric: \"tokens seen\"=522291\n",
      "[4950] Metric: \"epoch\"=0\n",
      "[4950] Metric: \"progress percent\"=5.059797608095677\n",
      "[4980] Metric: \"training loss\"=2.98873233795166\n",
      "[4980] Metric: \"learning rate\"=2.5452315240723705e-05\n",
      "[4980] Metric: \"tokens seen\"=525261\n",
      "[4980] Metric: \"epoch\"=0\n",
      "[4980] Metric: \"progress percent\"=5.090463048144741\n",
      "[5000] Example (example): \"The man that's turned it's likely for another girl\n",
      "They've done!\n",
      "They don't get on now in time\n",
      "they come on the right for me to take in what the boy would do to live content. Once, for three of our lives, we need to work with each other up there this time.\"\n",
      "[5010] Metric: \"training loss\"=4.24821138381958\n",
      "[5010] Metric: \"learning rate\"=2.560564244096903e-05\n",
      "[5010] Metric: \"tokens seen\"=528283\n",
      "[5010] Metric: \"epoch\"=0\n",
      "[5010] Metric: \"progress percent\"=5.121128488193805\n",
      "[5040] Metric: \"training loss\"=1.1220136880874634\n",
      "[5040] Metric: \"learning rate\"=2.5758969641214353e-05\n",
      "[5040] Metric: \"tokens seen\"=532036\n",
      "[5040] Metric: \"epoch\"=0\n",
      "[5040] Metric: \"progress percent\"=5.151793928242871\n",
      "[5070] Metric: \"training loss\"=3.9909019470214844\n",
      "[5070] Metric: \"learning rate\"=2.5912296841459675e-05\n",
      "[5070] Metric: \"tokens seen\"=535146\n",
      "[5070] Metric: \"epoch\"=0\n",
      "[5070] Metric: \"progress percent\"=5.182459368291934\n",
      "[5100] Metric: \"training loss\"=3.8379597663879395\n",
      "[5100] Metric: \"learning rate\"=2.6065624041705e-05\n",
      "[5100] Metric: \"tokens seen\"=537938\n",
      "[5100] Metric: \"epoch\"=0\n",
      "[5100] Metric: \"progress percent\"=5.213124808341\n",
      "[5130] Metric: \"training loss\"=3.0735974311828613\n",
      "[5130] Metric: \"learning rate\"=2.6218951241950323e-05\n",
      "[5130] Metric: \"tokens seen\"=540891\n",
      "[5130] Metric: \"epoch\"=0\n",
      "[5130] Metric: \"progress percent\"=5.243790248390065\n",
      "[5160] Metric: \"training loss\"=3.050487518310547\n",
      "[5160] Metric: \"learning rate\"=2.6372278442195645e-05\n",
      "[5160] Metric: \"tokens seen\"=544068\n",
      "[5160] Metric: \"epoch\"=0\n",
      "[5160] Metric: \"progress percent\"=5.274455688439129\n",
      "[5190] Metric: \"training loss\"=3.644033193588257\n",
      "[5190] Metric: \"learning rate\"=2.652560564244097e-05\n",
      "[5190] Metric: \"tokens seen\"=547155\n",
      "[5190] Metric: \"epoch\"=0\n",
      "[5190] Metric: \"progress percent\"=5.305121128488194\n",
      "[5200] Example (example): \"An \n",
      "\n",
      "List 1 to 20 \n",
      "2x 22  -   =  x lx2 \n",
      "2x 1/2x 8 c^0 c + = \n",
      "7x 2/3x 1)  \"  { \n",
      "Life  He \n",
      "Eccie  -   ____ \n",
      "\n",
      "Life  x 1,  =  | Son i \n",
      " Life   ________________ is Life 0\n",
      "Fought \n",
      "\n",
      "Life \n",
      "Ren i x i - 3, \n",
      "Night  is Life 10:|  | Son i   <10 + Ingen\"\n",
      "[5220] Metric: \"training loss\"=1.98825204372406\n",
      "[5220] Metric: \"learning rate\"=2.6678932842686293e-05\n",
      "[5220] Metric: \"tokens seen\"=550713\n",
      "[5220] Metric: \"epoch\"=0\n",
      "[5220] Metric: \"progress percent\"=5.335786568537258\n",
      "[5250] Metric: \"training loss\"=3.5632946491241455\n",
      "[5250] Metric: \"learning rate\"=2.683226004293162e-05\n",
      "[5250] Metric: \"tokens seen\"=554319\n",
      "[5250] Metric: \"epoch\"=0\n",
      "[5250] Metric: \"progress percent\"=5.366452008586323\n",
      "[5280] Metric: \"training loss\"=3.0743813514709473\n",
      "[5280] Metric: \"learning rate\"=2.698558724317694e-05\n",
      "[5280] Metric: \"tokens seen\"=557503\n",
      "[5280] Metric: \"epoch\"=0\n",
      "[5280] Metric: \"progress percent\"=5.397117448635388\n",
      "[5310] Metric: \"training loss\"=2.41530442237854\n",
      "[5310] Metric: \"learning rate\"=2.7138914443422263e-05\n",
      "[5310] Metric: \"tokens seen\"=560622\n",
      "[5310] Metric: \"epoch\"=0\n",
      "[5310] Metric: \"progress percent\"=5.427782888684453\n",
      "[5340] Metric: \"training loss\"=1.1802958250045776\n",
      "[5340] Metric: \"learning rate\"=2.729224164366759e-05\n",
      "[5340] Metric: \"tokens seen\"=563526\n",
      "[5340] Metric: \"epoch\"=0\n",
      "[5340] Metric: \"progress percent\"=5.4584483287335175\n",
      "[5370] Metric: \"training loss\"=3.666057586669922\n",
      "[5370] Metric: \"learning rate\"=2.744556884391291e-05\n",
      "[5370] Metric: \"tokens seen\"=566906\n",
      "[5370] Metric: \"epoch\"=0\n",
      "[5370] Metric: \"progress percent\"=5.489113768782582\n",
      "[5400] Metric: \"training loss\"=1.5119190216064453\n",
      "[5400] Metric: \"learning rate\"=2.7598896044158233e-05\n",
      "[5400] Metric: \"tokens seen\"=570158\n",
      "[5400] Metric: \"epoch\"=0\n",
      "[5400] Metric: \"progress percent\"=5.519779208831647\n",
      "[5400] Example (example): \"LUCASANT AND HIS NEPH.\n",
      "Birds the phrase from their base tone or shape would also illustrate natural characteristics. A certain verb was an imperative meaning that could create a personal effect towards life. The adjective in the main implies a natural expression that could suggest or create a common perception of human or animals's identity, which in future were possible for any man, such as a mental perception, or the sense of something or nothing. Other forms to express their validity might generate a certain distinct and definite perception of genetic significance, or are not associated to a new sentence by different expressions and with their corresponding and distinct ideas connected with\"\n",
      "[5400] Metric: \"validation loss\"=2.8375729521115622\n",
      "[5430] Metric: \"training loss\"=2.0765902996063232\n",
      "[5430] Metric: \"learning rate\"=2.775222324440356e-05\n",
      "[5430] Metric: \"tokens seen\"=573705\n",
      "[5430] Metric: \"epoch\"=0\n",
      "[5430] Metric: \"progress percent\"=5.5504446488807115\n",
      "[5460] Metric: \"training loss\"=2.341892719268799\n",
      "[5460] Metric: \"learning rate\"=2.790555044464888e-05\n",
      "[5460] Metric: \"tokens seen\"=576757\n",
      "[5460] Metric: \"epoch\"=0\n",
      "[5460] Metric: \"progress percent\"=5.581110088929776\n",
      "[5490] Metric: \"training loss\"=1.8205351829528809\n",
      "[5490] Metric: \"learning rate\"=2.8058877644894203e-05\n",
      "[5490] Metric: \"tokens seen\"=579698\n",
      "[5490] Metric: \"epoch\"=0\n",
      "[5490] Metric: \"progress percent\"=5.611775528978841\n",
      "[5520] Metric: \"training loss\"=1.7680690288543701\n",
      "[5520] Metric: \"learning rate\"=2.821220484513953e-05\n",
      "[5520] Metric: \"tokens seen\"=582832\n",
      "[5520] Metric: \"epoch\"=0\n",
      "[5520] Metric: \"progress percent\"=5.642440969027906\n",
      "[5550] Metric: \"training loss\"=3.34248685836792\n",
      "[5550] Metric: \"learning rate\"=2.836553204538485e-05\n",
      "[5550] Metric: \"tokens seen\"=585967\n",
      "[5550] Metric: \"epoch\"=0\n",
      "[5550] Metric: \"progress percent\"=5.67310640907697\n",
      "[5580] Metric: \"training loss\"=1.582377314567566\n",
      "[5580] Metric: \"learning rate\"=2.8518859245630177e-05\n",
      "[5580] Metric: \"tokens seen\"=589426\n",
      "[5580] Metric: \"epoch\"=0\n",
      "[5580] Metric: \"progress percent\"=5.703771849126035\n",
      "[5600] Example (example): \"fermantic):\n",
      "fermful:\n",
      "forgo is pleasant and pleasant. I only enjoy going! That's good of you! I can sit it right about her!\n",
      "My stay isn't bad. In this way does come too! I care no time or way to live content. The world makes her lonely so I keep quiet,\n",
      "it's happiness is going to look through life through all day!\n",
      "I hope I never will be in love without some day! I'd a feeling of hope there can be time coming back again to you!\"\n",
      "[5610] Metric: \"training loss\"=3.7947092056274414\n",
      "[5610] Metric: \"learning rate\"=2.86721864458755e-05\n",
      "[5610] Metric: \"tokens seen\"=592493\n",
      "[5610] Metric: \"epoch\"=0\n",
      "[5610] Metric: \"progress percent\"=5.7344372891751\n",
      "[5640] Metric: \"training loss\"=3.952791452407837\n",
      "[5640] Metric: \"learning rate\"=2.882551364612082e-05\n",
      "[5640] Metric: \"tokens seen\"=595233\n",
      "[5640] Metric: \"epoch\"=0\n",
      "[5640] Metric: \"progress percent\"=5.765102729224164\n",
      "[5670] Metric: \"training loss\"=2.9765748977661133\n",
      "[5670] Metric: \"learning rate\"=2.8978840846366147e-05\n",
      "[5670] Metric: \"tokens seen\"=598719\n",
      "[5670] Metric: \"epoch\"=0\n",
      "[5670] Metric: \"progress percent\"=5.795768169273229\n",
      "[5700] Metric: \"training loss\"=3.7497622966766357\n",
      "[5700] Metric: \"learning rate\"=2.913216804661147e-05\n",
      "[5700] Metric: \"tokens seen\"=601867\n",
      "[5700] Metric: \"epoch\"=0\n",
      "[5700] Metric: \"progress percent\"=5.826433609322294\n",
      "[5730] Metric: \"training loss\"=1.709396481513977\n",
      "[5730] Metric: \"learning rate\"=2.928549524685679e-05\n",
      "[5730] Metric: \"tokens seen\"=604739\n",
      "[5730] Metric: \"epoch\"=0\n",
      "[5730] Metric: \"progress percent\"=5.857099049371358\n",
      "[5760] Metric: \"training loss\"=2.1327669620513916\n",
      "[5760] Metric: \"learning rate\"=2.9438822447102116e-05\n",
      "[5760] Metric: \"tokens seen\"=607856\n",
      "[5760] Metric: \"epoch\"=0\n",
      "[5760] Metric: \"progress percent\"=5.887764489420423\n",
      "[5790] Metric: \"training loss\"=3.6442596912384033\n",
      "[5790] Metric: \"learning rate\"=2.959214964734744e-05\n",
      "[5790] Metric: \"tokens seen\"=610848\n",
      "[5790] Metric: \"epoch\"=0\n",
      "[5790] Metric: \"progress percent\"=5.918429929469489\n",
      "[5800] Example (example): \"presents: they will be patient and careful,\n",
      "pows and their time of action. A person is likely to know just how the person is safe in order\n",
      "pows on his energy.\"\n",
      "[5820] Metric: \"training loss\"=2.55495023727417\n",
      "[5820] Metric: \"learning rate\"=2.974547684759276e-05\n",
      "[5820] Metric: \"tokens seen\"=613969\n",
      "[5820] Metric: \"epoch\"=0\n",
      "[5820] Metric: \"progress percent\"=5.9490953695185524\n",
      "[5850] Metric: \"training loss\"=1.5935055017471313\n",
      "[5850] Metric: \"learning rate\"=2.9898804047838086e-05\n",
      "[5850] Metric: \"tokens seen\"=617209\n",
      "[5850] Metric: \"epoch\"=0\n",
      "[5850] Metric: \"progress percent\"=5.979760809567617\n",
      "[5880] Metric: \"training loss\"=3.687274932861328\n",
      "[5880] Metric: \"learning rate\"=3.005213124808341e-05\n",
      "[5880] Metric: \"tokens seen\"=620719\n",
      "[5880] Metric: \"epoch\"=0\n",
      "[5880] Metric: \"progress percent\"=6.010426249616682\n",
      "[5910] Metric: \"training loss\"=2.447263240814209\n",
      "[5910] Metric: \"learning rate\"=3.0205458448328734e-05\n",
      "[5910] Metric: \"tokens seen\"=623475\n",
      "[5910] Metric: \"epoch\"=0\n",
      "[5910] Metric: \"progress percent\"=6.0410916896657465\n",
      "[5940] Metric: \"training loss\"=3.03684401512146\n",
      "[5940] Metric: \"learning rate\"=3.0358785648574056e-05\n",
      "[5940] Metric: \"tokens seen\"=626349\n",
      "[5940] Metric: \"epoch\"=0\n",
      "[5940] Metric: \"progress percent\"=6.071757129714812\n",
      "[5970] Metric: \"training loss\"=2.9311940670013428\n",
      "[5970] Metric: \"learning rate\"=3.051211284881938e-05\n",
      "[5970] Metric: \"tokens seen\"=629095\n",
      "[5970] Metric: \"epoch\"=0\n",
      "[5970] Metric: \"progress percent\"=6.102422569763876\n",
      "[6000] Metric: \"training loss\"=2.7794346809387207\n",
      "[6000] Metric: \"learning rate\"=3.0665440049064704e-05\n",
      "[6000] Metric: \"tokens seen\"=632079\n",
      "[6000] Metric: \"epoch\"=0\n",
      "[6000] Metric: \"progress percent\"=6.1330880098129406\n",
      "[6000] Example (example): \"The sky is wet with a damp rain that breaks down in warm heat as the world turns with cold waterfalls. However this may pass also, the moon does not change and snow is growing hard and light as the sea breaks up like frost or frost. This is difficult for both Humans to follow the temperature at sunrise as heat falls short with cold for a while, and would be quite possible for a night's night day. The atmosphere will leave ice on and snow for a while to reach a temperature even while warm.\"\n",
      "[6000] Metric: \"validation loss\"=2.802349961271473\n",
      "[6030] Metric: \"training loss\"=2.2950198650360107\n",
      "[6030] Metric: \"learning rate\"=3.0818767249310026e-05\n",
      "[6030] Metric: \"tokens seen\"=635167\n",
      "[6030] Metric: \"epoch\"=0\n",
      "[6030] Metric: \"progress percent\"=6.163753449862005\n",
      "[6060] Metric: \"training loss\"=2.1398704051971436\n",
      "[6060] Metric: \"learning rate\"=3.097209444955535e-05\n",
      "[6060] Metric: \"tokens seen\"=638226\n",
      "[6060] Metric: \"epoch\"=0\n",
      "[6060] Metric: \"progress percent\"=6.19441888991107\n",
      "[6090] Metric: \"training loss\"=3.757073163986206\n",
      "[6090] Metric: \"learning rate\"=3.112542164980067e-05\n",
      "[6090] Metric: \"tokens seen\"=641711\n",
      "[6090] Metric: \"epoch\"=0\n",
      "[6090] Metric: \"progress percent\"=6.2250843299601355\n",
      "[6120] Metric: \"training loss\"=3.147686719894409\n",
      "[6120] Metric: \"learning rate\"=3.1278748850046e-05\n",
      "[6120] Metric: \"tokens seen\"=644667\n",
      "[6120] Metric: \"epoch\"=0\n",
      "[6120] Metric: \"progress percent\"=6.2557497700092\n",
      "[6150] Metric: \"training loss\"=4.678039073944092\n",
      "[6150] Metric: \"learning rate\"=3.143207605029133e-05\n",
      "[6150] Metric: \"tokens seen\"=648159\n",
      "[6150] Metric: \"epoch\"=0\n",
      "[6150] Metric: \"progress percent\"=6.286415210058265\n",
      "[6180] Metric: \"training loss\"=2.9201183319091797\n",
      "[6180] Metric: \"learning rate\"=3.158540325053665e-05\n",
      "[6180] Metric: \"tokens seen\"=651487\n",
      "[6180] Metric: \"epoch\"=0\n",
      "[6180] Metric: \"progress percent\"=6.317080650107329\n",
      "[6200] Example (example): \"This sentence is very appropriate and includes a type of formal expression. \n",
      "An idea like a sentence has the effect upon you for many sentences about the subject that you should use!  And a thing to help the person have a way to take care of?  What? \n",
      "A piece of card you like on purpose? \n",
      "A little bit of word is a sentence that follows a given sentence for making use in your vocabulary?  We believe you think that you'll like to write as the topic. \n",
      "\n",
      "This idea isn't important that way I ask how we get an original meaning for it: You don't count\"\n",
      "[6210] Metric: \"training loss\"=2.9998836517333984\n",
      "[6210] Metric: \"learning rate\"=3.173873045078197e-05\n",
      "[6210] Metric: \"tokens seen\"=654140\n",
      "[6210] Metric: \"epoch\"=0\n",
      "[6210] Metric: \"progress percent\"=6.347746090156393\n",
      "[6240] Metric: \"training loss\"=3.113191604614258\n",
      "[6240] Metric: \"learning rate\"=3.1892057651027295e-05\n",
      "[6240] Metric: \"tokens seen\"=656740\n",
      "[6240] Metric: \"epoch\"=0\n",
      "[6240] Metric: \"progress percent\"=6.378411530205458\n",
      "[6270] Metric: \"training loss\"=1.3954582214355469\n",
      "[6270] Metric: \"learning rate\"=3.204538485127262e-05\n",
      "[6270] Metric: \"tokens seen\"=660309\n",
      "[6270] Metric: \"epoch\"=0\n",
      "[6270] Metric: \"progress percent\"=6.409076970254524\n",
      "[6300] Metric: \"training loss\"=3.666640520095825\n",
      "[6300] Metric: \"learning rate\"=3.219871205151794e-05\n",
      "[6300] Metric: \"tokens seen\"=663459\n",
      "[6300] Metric: \"epoch\"=0\n",
      "[6300] Metric: \"progress percent\"=6.439742410303588\n",
      "[6330] Metric: \"training loss\"=2.152589797973633\n",
      "[6330] Metric: \"learning rate\"=3.235203925176327e-05\n",
      "[6330] Metric: \"tokens seen\"=666692\n",
      "[6330] Metric: \"epoch\"=0\n",
      "[6330] Metric: \"progress percent\"=6.470407850352652\n",
      "[6360] Metric: \"training loss\"=2.300959587097168\n",
      "[6360] Metric: \"learning rate\"=3.250536645200859e-05\n",
      "[6360] Metric: \"tokens seen\"=670166\n",
      "[6360] Metric: \"epoch\"=0\n",
      "[6360] Metric: \"progress percent\"=6.501073290401717\n",
      "[6390] Metric: \"training loss\"=3.7146401405334473\n",
      "[6390] Metric: \"learning rate\"=3.265869365225391e-05\n",
      "[6390] Metric: \"tokens seen\"=673262\n",
      "[6390] Metric: \"epoch\"=0\n",
      "[6390] Metric: \"progress percent\"=6.531738730450782\n",
      "[6400] Example (example): \"The noun of a verb could \"fordant\" include a stringy font or some new language-sentence to the original function.\" The carding given speech or to the noun in a simple, soft tone and expression for its significance is a long stringing device used to identify a feature for a type of rhythm.\"\n",
      "[6420] Metric: \"training loss\"=3.740365505218506\n",
      "[6420] Metric: \"learning rate\"=3.2812020852499235e-05\n",
      "[6420] Metric: \"tokens seen\"=676530\n",
      "[6420] Metric: \"epoch\"=0\n",
      "[6420] Metric: \"progress percent\"=6.562404170499847\n",
      "[6450] Metric: \"training loss\"=4.504938125610352\n",
      "[6450] Metric: \"learning rate\"=3.296534805274456e-05\n",
      "[6450] Metric: \"tokens seen\"=679224\n",
      "[6450] Metric: \"epoch\"=0\n",
      "[6450] Metric: \"progress percent\"=6.593069610548912\n",
      "[6480] Metric: \"training loss\"=3.4251368045806885\n",
      "[6480] Metric: \"learning rate\"=3.3118675252989887e-05\n",
      "[6480] Metric: \"tokens seen\"=682476\n",
      "[6480] Metric: \"epoch\"=0\n",
      "[6480] Metric: \"progress percent\"=6.6237350505979755\n",
      "[6510] Metric: \"training loss\"=2.467770576477051\n",
      "[6510] Metric: \"learning rate\"=3.327200245323521e-05\n",
      "[6510] Metric: \"tokens seen\"=685804\n",
      "[6510] Metric: \"epoch\"=0\n",
      "[6510] Metric: \"progress percent\"=6.65440049064704\n",
      "[6540] Metric: \"training loss\"=2.8317761421203613\n",
      "[6540] Metric: \"learning rate\"=3.342532965348053e-05\n",
      "[6540] Metric: \"tokens seen\"=689078\n",
      "[6540] Metric: \"epoch\"=0\n",
      "[6540] Metric: \"progress percent\"=6.685065930696106\n",
      "[6570] Metric: \"training loss\"=3.0793633460998535\n",
      "[6570] Metric: \"learning rate\"=3.357865685372585e-05\n",
      "[6570] Metric: \"tokens seen\"=692115\n",
      "[6570] Metric: \"epoch\"=0\n",
      "[6570] Metric: \"progress percent\"=6.7157313707451705\n",
      "[6600] Metric: \"training loss\"=3.8449461460113525\n",
      "[6600] Metric: \"learning rate\"=3.3731984053971175e-05\n",
      "[6600] Metric: \"tokens seen\"=695326\n",
      "[6600] Metric: \"epoch\"=0\n",
      "[6600] Metric: \"progress percent\"=6.746396810794235\n",
      "[6600] Example (example): \"fautious? input\"\n",
      "[6600] Metric: \"validation loss\"=2.7574515155717436\n",
      "[6630] Metric: \"training loss\"=2.092480421066284\n",
      "[6630] Metric: \"learning rate\"=3.38853112542165e-05\n",
      "[6630] Metric: \"tokens seen\"=698765\n",
      "[6630] Metric: \"epoch\"=0\n",
      "[6630] Metric: \"progress percent\"=6.777062250843299\n",
      "[6660] Metric: \"training loss\"=1.8797768354415894\n",
      "[6660] Metric: \"learning rate\"=3.4038638454461827e-05\n",
      "[6660] Metric: \"tokens seen\"=701759\n",
      "[6660] Metric: \"epoch\"=0\n",
      "[6660] Metric: \"progress percent\"=6.807727690892364\n",
      "[6690] Metric: \"training loss\"=1.4370417594909668\n",
      "[6690] Metric: \"learning rate\"=3.419196565470715e-05\n",
      "[6690] Metric: \"tokens seen\"=704904\n",
      "[6690] Metric: \"epoch\"=0\n",
      "[6690] Metric: \"progress percent\"=6.838393130941429\n",
      "[6720] Metric: \"training loss\"=2.055864095687866\n",
      "[6720] Metric: \"learning rate\"=3.434529285495247e-05\n",
      "[6720] Metric: \"tokens seen\"=707955\n",
      "[6720] Metric: \"epoch\"=0\n",
      "[6720] Metric: \"progress percent\"=6.869058570990494\n",
      "[6750] Metric: \"training loss\"=2.673766851425171\n",
      "[6750] Metric: \"learning rate\"=3.449862005519779e-05\n",
      "[6750] Metric: \"tokens seen\"=711911\n",
      "[6750] Metric: \"epoch\"=0\n",
      "[6750] Metric: \"progress percent\"=6.899724011039559\n",
      "[6780] Metric: \"training loss\"=4.157241344451904\n",
      "[6780] Metric: \"learning rate\"=3.4651947255443115e-05\n",
      "[6780] Metric: \"tokens seen\"=715299\n",
      "[6780] Metric: \"epoch\"=0\n",
      "[6780] Metric: \"progress percent\"=6.930389451088622\n",
      "[6800] Example (example): \"fascacious\"\n",
      "[6810] Metric: \"training loss\"=2.7360401153564453\n",
      "[6810] Metric: \"learning rate\"=3.4805274455688444e-05\n",
      "[6810] Metric: \"tokens seen\"=718782\n",
      "[6810] Metric: \"epoch\"=0\n",
      "[6810] Metric: \"progress percent\"=6.961054891137689\n",
      "[6840] Metric: \"training loss\"=2.13272762298584\n",
      "[6840] Metric: \"learning rate\"=3.4958601655933767e-05\n",
      "[6840] Metric: \"tokens seen\"=722429\n",
      "[6840] Metric: \"epoch\"=0\n",
      "[6840] Metric: \"progress percent\"=6.991720331186753\n",
      "[6870] Metric: \"training loss\"=2.110039234161377\n",
      "[6870] Metric: \"learning rate\"=3.511192885617909e-05\n",
      "[6870] Metric: \"tokens seen\"=725322\n",
      "[6870] Metric: \"epoch\"=0\n",
      "[6870] Metric: \"progress percent\"=7.022385771235817\n",
      "[6900] Metric: \"training loss\"=2.4039554595947266\n",
      "[6900] Metric: \"learning rate\"=3.526525605642441e-05\n",
      "[6900] Metric: \"tokens seen\"=728443\n",
      "[6900] Metric: \"epoch\"=0\n",
      "[6900] Metric: \"progress percent\"=7.053051211284882\n",
      "[6930] Metric: \"training loss\"=2.556577682495117\n",
      "[6930] Metric: \"learning rate\"=3.541858325666973e-05\n",
      "[6930] Metric: \"tokens seen\"=731506\n",
      "[6930] Metric: \"epoch\"=0\n",
      "[6930] Metric: \"progress percent\"=7.083716651333946\n",
      "[6960] Metric: \"training loss\"=2.8178646564483643\n",
      "[6960] Metric: \"learning rate\"=3.5571910456915055e-05\n",
      "[6960] Metric: \"tokens seen\"=734736\n",
      "[6960] Metric: \"epoch\"=0\n",
      "[6960] Metric: \"progress percent\"=7.114382091383012\n",
      "[6990] Metric: \"training loss\"=3.613616704940796\n",
      "[6990] Metric: \"learning rate\"=3.5725237657160384e-05\n",
      "[6990] Metric: \"tokens seen\"=738080\n",
      "[6990] Metric: \"epoch\"=0\n",
      "[6990] Metric: \"progress percent\"=7.145047531432076\n",
      "[7000] Example (example): \"Unmasked with new ideas\n",
      "Consecrated with his own image,\"\n",
      "[7020] Metric: \"training loss\"=2.5670533180236816\n",
      "[7020] Metric: \"learning rate\"=3.5878564857405706e-05\n",
      "[7020] Metric: \"tokens seen\"=741113\n",
      "[7020] Metric: \"epoch\"=0\n",
      "[7020] Metric: \"progress percent\"=7.175712971481141\n",
      "[7050] Metric: \"training loss\"=2.7751851081848145\n",
      "[7050] Metric: \"learning rate\"=3.603189205765103e-05\n",
      "[7050] Metric: \"tokens seen\"=744614\n",
      "[7050] Metric: \"epoch\"=0\n",
      "[7050] Metric: \"progress percent\"=7.206378411530205\n",
      "[7080] Metric: \"training loss\"=3.164661169052124\n",
      "[7080] Metric: \"learning rate\"=3.618521925789635e-05\n",
      "[7080] Metric: \"tokens seen\"=747709\n",
      "[7080] Metric: \"epoch\"=0\n",
      "[7080] Metric: \"progress percent\"=7.237043851579269\n",
      "[7110] Metric: \"training loss\"=2.6798157691955566\n",
      "[7110] Metric: \"learning rate\"=3.633854645814167e-05\n",
      "[7110] Metric: \"tokens seen\"=750954\n",
      "[7110] Metric: \"epoch\"=0\n",
      "[7110] Metric: \"progress percent\"=7.267709291628336\n",
      "[7140] Metric: \"training loss\"=3.4061660766601562\n",
      "[7140] Metric: \"learning rate\"=3.6491873658387e-05\n",
      "[7140] Metric: \"tokens seen\"=754259\n",
      "[7140] Metric: \"epoch\"=0\n",
      "[7140] Metric: \"progress percent\"=7.2983747316773995\n",
      "[7170] Metric: \"training loss\"=1.4901365041732788\n",
      "[7170] Metric: \"learning rate\"=3.6645200858632324e-05\n",
      "[7170] Metric: \"tokens seen\"=757267\n",
      "[7170] Metric: \"epoch\"=0\n",
      "[7170] Metric: \"progress percent\"=7.329040171726464\n",
      "[7200] Metric: \"training loss\"=1.8107060194015503\n",
      "[7200] Metric: \"learning rate\"=3.6798528058877646e-05\n",
      "[7200] Metric: \"tokens seen\"=760568\n",
      "[7200] Metric: \"epoch\"=0\n",
      "[7200] Metric: \"progress percent\"=7.359705611775529\n",
      "[7200] Example (example): \"I was walking home with an old dog.\"\n",
      "[7200] Metric: \"validation loss\"=2.722924746719061\n",
      "[7230] Metric: \"training loss\"=4.589489936828613\n",
      "[7230] Metric: \"learning rate\"=3.695185525912297e-05\n",
      "[7230] Metric: \"tokens seen\"=763887\n",
      "[7230] Metric: \"epoch\"=0\n",
      "[7230] Metric: \"progress percent\"=7.390371051824594\n",
      "[7260] Metric: \"training loss\"=1.974596619606018\n",
      "[7260] Metric: \"learning rate\"=3.710518245936829e-05\n",
      "[7260] Metric: \"tokens seen\"=767214\n",
      "[7260] Metric: \"epoch\"=0\n",
      "[7260] Metric: \"progress percent\"=7.421036491873659\n",
      "[7290] Metric: \"training loss\"=3.4585635662078857\n",
      "[7290] Metric: \"learning rate\"=3.725850965961361e-05\n",
      "[7290] Metric: \"tokens seen\"=771001\n",
      "[7290] Metric: \"epoch\"=0\n",
      "[7290] Metric: \"progress percent\"=7.451701931922723\n",
      "[7320] Metric: \"training loss\"=2.183178424835205\n",
      "[7320] Metric: \"learning rate\"=3.741183685985894e-05\n",
      "[7320] Metric: \"tokens seen\"=774084\n",
      "[7320] Metric: \"epoch\"=0\n",
      "[7320] Metric: \"progress percent\"=7.482367371971788\n",
      "[7350] Metric: \"training loss\"=1.573533296585083\n",
      "[7350] Metric: \"learning rate\"=3.7565164060104264e-05\n",
      "[7350] Metric: \"tokens seen\"=777117\n",
      "[7350] Metric: \"epoch\"=0\n",
      "[7350] Metric: \"progress percent\"=7.513032812020852\n",
      "[7380] Metric: \"training loss\"=2.083156108856201\n",
      "[7380] Metric: \"learning rate\"=3.7718491260349586e-05\n",
      "[7380] Metric: \"tokens seen\"=780273\n",
      "[7380] Metric: \"epoch\"=0\n",
      "[7380] Metric: \"progress percent\"=7.543698252069918\n",
      "[7400] Example (example): \"favishness\n",
      "jub-stealing\"\n",
      "[7410] Metric: \"training loss\"=3.678609609603882\n",
      "[7410] Metric: \"learning rate\"=3.787181846059491e-05\n",
      "[7410] Metric: \"tokens seen\"=783342\n",
      "[7410] Metric: \"epoch\"=0\n",
      "[7410] Metric: \"progress percent\"=7.5743636921189825\n",
      "[7440] Metric: \"training loss\"=1.5969583988189697\n",
      "[7440] Metric: \"learning rate\"=3.802514566084023e-05\n",
      "[7440] Metric: \"tokens seen\"=786687\n",
      "[7440] Metric: \"epoch\"=0\n",
      "[7440] Metric: \"progress percent\"=7.605029132168046\n",
      "[7470] Metric: \"training loss\"=1.8973495960235596\n",
      "[7470] Metric: \"learning rate\"=3.817847286108556e-05\n",
      "[7470] Metric: \"tokens seen\"=789887\n",
      "[7470] Metric: \"epoch\"=0\n",
      "[7470] Metric: \"progress percent\"=7.635694572217111\n",
      "[7500] Metric: \"training loss\"=3.0922718048095703\n",
      "[7500] Metric: \"learning rate\"=3.833180006133088e-05\n",
      "[7500] Metric: \"tokens seen\"=792957\n",
      "[7500] Metric: \"epoch\"=0\n",
      "[7500] Metric: \"progress percent\"=7.666360012266176\n",
      "[7530] Metric: \"training loss\"=2.3980746269226074\n",
      "[7530] Metric: \"learning rate\"=3.8485127261576204e-05\n",
      "[7530] Metric: \"tokens seen\"=796230\n",
      "[7530] Metric: \"epoch\"=0\n",
      "[7530] Metric: \"progress percent\"=7.697025452315241\n",
      "[7560] Metric: \"training loss\"=2.399599075317383\n",
      "[7560] Metric: \"learning rate\"=3.8638454461821526e-05\n",
      "[7560] Metric: \"tokens seen\"=798939\n",
      "[7560] Metric: \"epoch\"=0\n",
      "[7560] Metric: \"progress percent\"=7.727690892364306\n",
      "[7590] Metric: \"training loss\"=3.0126399993896484\n",
      "[7590] Metric: \"learning rate\"=3.879178166206685e-05\n",
      "[7590] Metric: \"tokens seen\"=802161\n",
      "[7590] Metric: \"epoch\"=0\n",
      "[7590] Metric: \"progress percent\"=7.75835633241337\n",
      "[7600] Example (example): \"I think it the best chance.\"\n",
      "[7620] Metric: \"training loss\"=2.635253429412842\n",
      "[7620] Metric: \"learning rate\"=3.894510886231217e-05\n",
      "[7620] Metric: \"tokens seen\"=804848\n",
      "[7620] Metric: \"epoch\"=0\n",
      "[7620] Metric: \"progress percent\"=7.789021772462434\n",
      "[7650] Metric: \"training loss\"=2.020906925201416\n",
      "[7650] Metric: \"learning rate\"=3.90984360625575e-05\n",
      "[7650] Metric: \"tokens seen\"=807490\n",
      "[7650] Metric: \"epoch\"=0\n",
      "[7650] Metric: \"progress percent\"=7.8196872125115\n",
      "[7680] Metric: \"training loss\"=3.0605685710906982\n",
      "[7680] Metric: \"learning rate\"=3.925176326280282e-05\n",
      "[7680] Metric: \"tokens seen\"=810554\n",
      "[7680] Metric: \"epoch\"=0\n",
      "[7680] Metric: \"progress percent\"=7.850352652560565\n",
      "[7710] Metric: \"training loss\"=4.018787860870361\n",
      "[7710] Metric: \"learning rate\"=3.9405090463048144e-05\n",
      "[7710] Metric: \"tokens seen\"=813693\n",
      "[7710] Metric: \"epoch\"=0\n",
      "[7710] Metric: \"progress percent\"=7.881018092609629\n",
      "[7740] Metric: \"training loss\"=2.4177868366241455\n",
      "[7740] Metric: \"learning rate\"=3.9558417663293466e-05\n",
      "[7740] Metric: \"tokens seen\"=816331\n",
      "[7740] Metric: \"epoch\"=0\n",
      "[7740] Metric: \"progress percent\"=7.911683532658693\n",
      "[7770] Metric: \"training loss\"=1.3637151718139648\n",
      "[7770] Metric: \"learning rate\"=3.971174486353879e-05\n",
      "[7770] Metric: \"tokens seen\"=819590\n",
      "[7770] Metric: \"epoch\"=0\n",
      "[7770] Metric: \"progress percent\"=7.942348972707758\n",
      "[7800] Metric: \"training loss\"=1.177628755569458\n",
      "[7800] Metric: \"learning rate\"=3.986507206378412e-05\n",
      "[7800] Metric: \"tokens seen\"=822871\n",
      "[7800] Metric: \"epoch\"=0\n",
      "[7800] Metric: \"progress percent\"=7.973014412756823\n",
      "[7800] Example (example): \"My own\n",
      "He did not speak to them, but turned His voice across them both. As they drew the table, he jumped up quickly by taking the chair to eat the lunch into his hands. To begin a conversation, he then sat down and rested His hand upon their shoulder.\"\n",
      "[7800] Metric: \"validation loss\"=2.699597514143177\n",
      "[7830] Metric: \"training loss\"=3.696810007095337\n",
      "[7830] Metric: \"learning rate\"=4.001839926402944e-05\n",
      "[7830] Metric: \"tokens seen\"=826403\n",
      "[7830] Metric: \"epoch\"=0\n",
      "[7830] Metric: \"progress percent\"=8.003679852805888\n",
      "[7860] Metric: \"training loss\"=2.437154531478882\n",
      "[7860] Metric: \"learning rate\"=4.017172646427476e-05\n",
      "[7860] Metric: \"tokens seen\"=829304\n",
      "[7860] Metric: \"epoch\"=0\n",
      "[7860] Metric: \"progress percent\"=8.034345292854953\n",
      "[7890] Metric: \"training loss\"=2.4827189445495605\n",
      "[7890] Metric: \"learning rate\"=4.032505366452009e-05\n",
      "[7890] Metric: \"tokens seen\"=832401\n",
      "[7890] Metric: \"epoch\"=0\n",
      "[7890] Metric: \"progress percent\"=8.065010732904017\n",
      "[7920] Metric: \"training loss\"=3.6212379932403564\n",
      "[7920] Metric: \"learning rate\"=4.047838086476541e-05\n",
      "[7920] Metric: \"tokens seen\"=836413\n",
      "[7920] Metric: \"epoch\"=0\n",
      "[7920] Metric: \"progress percent\"=8.09567617295308\n",
      "[7950] Metric: \"training loss\"=1.5459589958190918\n",
      "[7950] Metric: \"learning rate\"=4.0631708065010735e-05\n",
      "[7950] Metric: \"tokens seen\"=839474\n",
      "[7950] Metric: \"epoch\"=0\n",
      "[7950] Metric: \"progress percent\"=8.126341613002147\n",
      "[7980] Metric: \"training loss\"=1.5179853439331055\n",
      "[7980] Metric: \"learning rate\"=4.078503526525606e-05\n",
      "[7980] Metric: \"tokens seen\"=841874\n",
      "[7980] Metric: \"epoch\"=0\n",
      "[7980] Metric: \"progress percent\"=8.157007053051212\n",
      "[8000] Example (example): \"He opened his eyes and closed the gates before the new town became an important article. On his side he revealed his own idea in relation to his proposed plan and was accepted, followed after an opportunity. After studying, his purpose appeared to lead the decision, which was in the new town so that he resolved should return early to the factory. As for that case, the news began that he expected it to make it less time, so he turned to his business-like office-seekers. From the following moment, he finally reached the destination of his expectations and his instructions without waiting for his appointment.\n",
      "The idea in turn suggested to her\"\n",
      "[8010] Metric: \"training loss\"=2.3932576179504395\n",
      "[8010] Metric: \"learning rate\"=4.0938362465501387e-05\n",
      "[8010] Metric: \"tokens seen\"=844636\n",
      "[8010] Metric: \"epoch\"=0\n",
      "[8010] Metric: \"progress percent\"=8.187672493100276\n",
      "[8040] Metric: \"training loss\"=0.8489122986793518\n",
      "[8040] Metric: \"learning rate\"=4.109168966574671e-05\n",
      "[8040] Metric: \"tokens seen\"=847543\n",
      "[8040] Metric: \"epoch\"=0\n",
      "[8040] Metric: \"progress percent\"=8.218337933149341\n",
      "[8070] Metric: \"training loss\"=2.101867198944092\n",
      "[8070] Metric: \"learning rate\"=4.124501686599203e-05\n",
      "[8070] Metric: \"tokens seen\"=850875\n",
      "[8070] Metric: \"epoch\"=0\n",
      "[8070] Metric: \"progress percent\"=8.249003373198406\n",
      "[8100] Metric: \"training loss\"=2.379230260848999\n",
      "[8100] Metric: \"learning rate\"=4.139834406623735e-05\n",
      "[8100] Metric: \"tokens seen\"=854184\n",
      "[8100] Metric: \"epoch\"=0\n",
      "[8100] Metric: \"progress percent\"=8.27966881324747\n",
      "[8130] Metric: \"training loss\"=1.627207636833191\n",
      "[8130] Metric: \"learning rate\"=4.1551671266482675e-05\n",
      "[8130] Metric: \"tokens seen\"=856813\n",
      "[8130] Metric: \"epoch\"=0\n",
      "[8130] Metric: \"progress percent\"=8.310334253296535\n",
      "[8160] Metric: \"training loss\"=3.2478623390197754\n",
      "[8160] Metric: \"learning rate\"=4.1704998466728004e-05\n",
      "[8160] Metric: \"tokens seen\"=859534\n",
      "[8160] Metric: \"epoch\"=0\n",
      "[8160] Metric: \"progress percent\"=8.3409996933456\n",
      "[8190] Metric: \"training loss\"=2.7622363567352295\n",
      "[8190] Metric: \"learning rate\"=4.1858325666973326e-05\n",
      "[8190] Metric: \"tokens seen\"=863447\n",
      "[8190] Metric: \"epoch\"=0\n",
      "[8190] Metric: \"progress percent\"=8.371665133394664\n",
      "[8200] Example (example): \"fup. SQL\"\n",
      "[8220] Metric: \"training loss\"=2.4215810298919678\n",
      "[8220] Metric: \"learning rate\"=4.201165286721865e-05\n",
      "[8220] Metric: \"tokens seen\"=866532\n",
      "[8220] Metric: \"epoch\"=0\n",
      "[8220] Metric: \"progress percent\"=8.402330573443729\n",
      "[8250] Metric: \"training loss\"=3.2796623706817627\n",
      "[8250] Metric: \"learning rate\"=4.216498006746397e-05\n",
      "[8250] Metric: \"tokens seen\"=869755\n",
      "[8250] Metric: \"epoch\"=0\n",
      "[8250] Metric: \"progress percent\"=8.432996013492794\n",
      "[8280] Metric: \"training loss\"=2.6288459300994873\n",
      "[8280] Metric: \"learning rate\"=4.231830726770929e-05\n",
      "[8280] Metric: \"tokens seen\"=872735\n",
      "[8280] Metric: \"epoch\"=0\n",
      "[8280] Metric: \"progress percent\"=8.463661453541858\n",
      "[8310] Metric: \"training loss\"=2.872056722640991\n",
      "[8310] Metric: \"learning rate\"=4.2471634467954615e-05\n",
      "[8310] Metric: \"tokens seen\"=876252\n",
      "[8310] Metric: \"epoch\"=0\n",
      "[8310] Metric: \"progress percent\"=8.494326893590923\n",
      "[8340] Metric: \"training loss\"=2.9433419704437256\n",
      "[8340] Metric: \"learning rate\"=4.2624961668199944e-05\n",
      "[8340] Metric: \"tokens seen\"=879086\n",
      "[8340] Metric: \"epoch\"=0\n",
      "[8340] Metric: \"progress percent\"=8.524992333639988\n",
      "[8370] Metric: \"training loss\"=2.4748642444610596\n",
      "[8370] Metric: \"learning rate\"=4.2778288868445266e-05\n",
      "[8370] Metric: \"tokens seen\"=881861\n",
      "[8370] Metric: \"epoch\"=0\n",
      "[8370] Metric: \"progress percent\"=8.555657773689052\n",
      "[8400] Metric: \"training loss\"=2.580099105834961\n",
      "[8400] Metric: \"learning rate\"=4.293161606869059e-05\n",
      "[8400] Metric: \"tokens seen\"=885493\n",
      "[8400] Metric: \"epoch\"=0\n",
      "[8400] Metric: \"progress percent\"=8.586323213738117\n",
      "[8400] Example (example): \"I was so excited that our conversation grew uneasy while the door was open and shut. I heard your words crunch. Finally, my mind was broken.\n",
      "But it did not turn away from you as I felt about my situation. Then, while I listened, the door was closed in on the darkness. Then one second, through the sound, the entrance door was closed, in as I saw a stranger. Suddenly a door opened and a door opened before I saw a stranger stepped past me. I caught my hand.\n",
      "I saw someone standing at their foot.\n",
      "\n",
      "Here was a key to me from you which touched you down.\"\n",
      "[8400] Metric: \"validation loss\"=2.66093258413614\n",
      "[8430] Metric: \"training loss\"=1.5537503957748413\n",
      "[8430] Metric: \"learning rate\"=4.308494326893591e-05\n",
      "[8430] Metric: \"tokens seen\"=888150\n",
      "[8430] Metric: \"epoch\"=0\n",
      "[8430] Metric: \"progress percent\"=8.616988653787182\n",
      "[8460] Metric: \"training loss\"=2.5868911743164062\n",
      "[8460] Metric: \"learning rate\"=4.323827046918123e-05\n",
      "[8460] Metric: \"tokens seen\"=891594\n",
      "[8460] Metric: \"epoch\"=0\n",
      "[8460] Metric: \"progress percent\"=8.647654093836247\n",
      "[8490] Metric: \"training loss\"=1.5595921277999878\n",
      "[8490] Metric: \"learning rate\"=4.339159766942656e-05\n",
      "[8490] Metric: \"tokens seen\"=894570\n",
      "[8490] Metric: \"epoch\"=0\n",
      "[8490] Metric: \"progress percent\"=8.678319533885311\n",
      "[8520] Metric: \"training loss\"=1.5010886192321777\n",
      "[8520] Metric: \"learning rate\"=4.3544924869671884e-05\n",
      "[8520] Metric: \"tokens seen\"=897467\n",
      "[8520] Metric: \"epoch\"=0\n",
      "[8520] Metric: \"progress percent\"=8.708984973934376\n",
      "[8550] Metric: \"training loss\"=3.6159541606903076\n",
      "[8550] Metric: \"learning rate\"=4.3698252069917206e-05\n",
      "[8550] Metric: \"tokens seen\"=900523\n",
      "[8550] Metric: \"epoch\"=0\n",
      "[8550] Metric: \"progress percent\"=8.73965041398344\n",
      "[8580] Metric: \"training loss\"=3.470842123031616\n",
      "[8580] Metric: \"learning rate\"=4.385157927016253e-05\n",
      "[8580] Metric: \"tokens seen\"=903892\n",
      "[8580] Metric: \"epoch\"=0\n",
      "[8580] Metric: \"progress percent\"=8.770315854032505\n",
      "[8600] Example (example): \"John likes walking and ride with a long stick walking by twitching his tail before entering them.\"\n",
      "[8610] Metric: \"training loss\"=1.424690842628479\n",
      "[8610] Metric: \"learning rate\"=4.400490647040785e-05\n",
      "[8610] Metric: \"tokens seen\"=906485\n",
      "[8610] Metric: \"epoch\"=0\n",
      "[8610] Metric: \"progress percent\"=8.80098129408157\n",
      "[8640] Metric: \"training loss\"=2.9842605590820312\n",
      "[8640] Metric: \"learning rate\"=4.415823367065317e-05\n",
      "[8640] Metric: \"tokens seen\"=909787\n",
      "[8640] Metric: \"epoch\"=0\n",
      "[8640] Metric: \"progress percent\"=8.831646734130635\n",
      "[8670] Metric: \"training loss\"=2.8133158683776855\n",
      "[8670] Metric: \"learning rate\"=4.43115608708985e-05\n",
      "[8670] Metric: \"tokens seen\"=913219\n",
      "[8670] Metric: \"epoch\"=0\n",
      "[8670] Metric: \"progress percent\"=8.8623121741797\n",
      "[8700] Metric: \"training loss\"=3.303652286529541\n",
      "[8700] Metric: \"learning rate\"=4.4464888071143824e-05\n",
      "[8700] Metric: \"tokens seen\"=916808\n",
      "[8700] Metric: \"epoch\"=0\n",
      "[8700] Metric: \"progress percent\"=8.892977614228764\n",
      "[8730] Metric: \"training loss\"=2.942709445953369\n",
      "[8730] Metric: \"learning rate\"=4.4618215271389146e-05\n",
      "[8730] Metric: \"tokens seen\"=920056\n",
      "[8730] Metric: \"epoch\"=0\n",
      "[8730] Metric: \"progress percent\"=8.923643054277829\n",
      "[8760] Metric: \"training loss\"=2.964301824569702\n",
      "[8760] Metric: \"learning rate\"=4.477154247163447e-05\n",
      "[8760] Metric: \"tokens seen\"=922891\n",
      "[8760] Metric: \"epoch\"=0\n",
      "[8760] Metric: \"progress percent\"=8.954308494326893\n",
      "[8790] Metric: \"training loss\"=2.191647529602051\n",
      "[8790] Metric: \"learning rate\"=4.492486967187979e-05\n",
      "[8790] Metric: \"tokens seen\"=926248\n",
      "[8790] Metric: \"epoch\"=0\n",
      "[8790] Metric: \"progress percent\"=8.984973934375958\n",
      "[8800] Example (example): \"Fructified in form from a given verb will do something else. As a new meaning is to help help friends make good company like friends. There can be some of you between learning to learn and study new language and write new songs from their teacher.\"\n",
      "[8820] Metric: \"training loss\"=1.8978139162063599\n",
      "[8820] Metric: \"learning rate\"=4.507819687212512e-05\n",
      "[8820] Metric: \"tokens seen\"=929061\n",
      "[8820] Metric: \"epoch\"=0\n",
      "[8820] Metric: \"progress percent\"=9.015639374425023\n",
      "[8850] Metric: \"training loss\"=1.725356101989746\n",
      "[8850] Metric: \"learning rate\"=4.523152407237044e-05\n",
      "[8850] Metric: \"tokens seen\"=932528\n",
      "[8850] Metric: \"epoch\"=0\n",
      "[8850] Metric: \"progress percent\"=9.046304814474087\n",
      "[8880] Metric: \"training loss\"=3.6340367794036865\n",
      "[8880] Metric: \"learning rate\"=4.5384851272615764e-05\n",
      "[8880] Metric: \"tokens seen\"=935654\n",
      "[8880] Metric: \"epoch\"=0\n",
      "[8880] Metric: \"progress percent\"=9.076970254523152\n",
      "[8910] Metric: \"training loss\"=1.4083282947540283\n",
      "[8910] Metric: \"learning rate\"=4.5538178472861086e-05\n",
      "[8910] Metric: \"tokens seen\"=938931\n",
      "[8910] Metric: \"epoch\"=0\n",
      "[8910] Metric: \"progress percent\"=9.107635694572217\n",
      "[8940] Metric: \"training loss\"=1.2390717267990112\n",
      "[8940] Metric: \"learning rate\"=4.569150567310641e-05\n",
      "[8940] Metric: \"tokens seen\"=941739\n",
      "[8940] Metric: \"epoch\"=0\n",
      "[8940] Metric: \"progress percent\"=9.138301134621281\n",
      "[8970] Metric: \"training loss\"=1.3720592260360718\n",
      "[8970] Metric: \"learning rate\"=4.584483287335173e-05\n",
      "[8970] Metric: \"tokens seen\"=944714\n",
      "[8970] Metric: \"epoch\"=0\n",
      "[8970] Metric: \"progress percent\"=9.168966574670346\n",
      "[9000] Metric: \"training loss\"=1.7850404977798462\n",
      "[9000] Metric: \"learning rate\"=4.599816007359706e-05\n",
      "[9000] Metric: \"tokens seen\"=947522\n",
      "[9000] Metric: \"epoch\"=0\n",
      "[9000] Metric: \"progress percent\"=9.19963201471941\n",
      "[9000] Example (example): \"A dog can feed around some one year, if they eat too full meal on their hungry little rabbit, so often they can’t be long-term. They can just walk around some farm while making a more cheerful show, as well as walking around the city. With their breakfast, they can stay hungry through hours of their early day. \n",
      "We eat their dogs, pick up large apples, eat their breakfasts and eat our rice, eat and have an appetite. Addie when making a break of food in the early morning with a family dinner to sleep after a meal, or enjoy their supper and return.\"\n",
      "[9000] Metric: \"validation loss\"=2.6383975078077877\n",
      "[9030] Metric: \"training loss\"=1.8178647756576538\n",
      "[9030] Metric: \"learning rate\"=4.615148727384238e-05\n",
      "[9030] Metric: \"tokens seen\"=950605\n",
      "[9030] Metric: \"epoch\"=0\n",
      "[9030] Metric: \"progress percent\"=9.230297454768476\n",
      "[9060] Metric: \"training loss\"=2.6683874130249023\n",
      "[9060] Metric: \"learning rate\"=4.6304814474087704e-05\n",
      "[9060] Metric: \"tokens seen\"=953699\n",
      "[9060] Metric: \"epoch\"=0\n",
      "[9060] Metric: \"progress percent\"=9.260962894817542\n",
      "[9090] Metric: \"training loss\"=1.8485547304153442\n",
      "[9090] Metric: \"learning rate\"=4.6458141674333026e-05\n",
      "[9090] Metric: \"tokens seen\"=956631\n",
      "[9090] Metric: \"epoch\"=0\n",
      "[9090] Metric: \"progress percent\"=9.291628334866605\n",
      "[9120] Metric: \"training loss\"=2.1530532836914062\n",
      "[9120] Metric: \"learning rate\"=4.661146887457835e-05\n",
      "[9120] Metric: \"tokens seen\"=959280\n",
      "[9120] Metric: \"epoch\"=0\n",
      "[9120] Metric: \"progress percent\"=9.32229377491567\n",
      "[9150] Metric: \"training loss\"=3.1664302349090576\n",
      "[9150] Metric: \"learning rate\"=4.676479607482368e-05\n",
      "[9150] Metric: \"tokens seen\"=961993\n",
      "[9150] Metric: \"epoch\"=0\n",
      "[9150] Metric: \"progress percent\"=9.352959214964734\n",
      "[9180] Metric: \"training loss\"=1.351717472076416\n",
      "[9180] Metric: \"learning rate\"=4.6918123275069e-05\n",
      "[9180] Metric: \"tokens seen\"=965143\n",
      "[9180] Metric: \"epoch\"=0\n",
      "[9180] Metric: \"progress percent\"=9.383624655013799\n",
      "[9200] Example (example): \"A dog is too long with his body on it. Additionally, he can jump at a pole about in a fashion when I don’t do it.\"\n",
      "[9210] Metric: \"training loss\"=3.4140756130218506\n",
      "[9210] Metric: \"learning rate\"=4.707145047531432e-05\n",
      "[9210] Metric: \"tokens seen\"=968196\n",
      "[9210] Metric: \"epoch\"=0\n",
      "[9210] Metric: \"progress percent\"=9.414290095062865\n",
      "[9240] Metric: \"training loss\"=3.127335548400879\n",
      "[9240] Metric: \"learning rate\"=4.7224777675559644e-05\n",
      "[9240] Metric: \"tokens seen\"=971398\n",
      "[9240] Metric: \"epoch\"=0\n",
      "[9240] Metric: \"progress percent\"=9.444955535111928\n",
      "[9270] Metric: \"training loss\"=2.0603435039520264\n",
      "[9270] Metric: \"learning rate\"=4.7378104875804966e-05\n",
      "[9270] Metric: \"tokens seen\"=974916\n",
      "[9270] Metric: \"epoch\"=0\n",
      "[9270] Metric: \"progress percent\"=9.475620975160993\n",
      "[9300] Metric: \"training loss\"=2.064713954925537\n",
      "[9300] Metric: \"learning rate\"=4.753143207605029e-05\n",
      "[9300] Metric: \"tokens seen\"=977859\n",
      "[9300] Metric: \"epoch\"=0\n",
      "[9300] Metric: \"progress percent\"=9.506286415210058\n",
      "[9330] Metric: \"training loss\"=2.439974546432495\n",
      "[9330] Metric: \"learning rate\"=4.768475927629562e-05\n",
      "[9330] Metric: \"tokens seen\"=980838\n",
      "[9330] Metric: \"epoch\"=0\n",
      "[9330] Metric: \"progress percent\"=9.536951855259122\n",
      "[9360] Metric: \"training loss\"=2.0782546997070312\n",
      "[9360] Metric: \"learning rate\"=4.783808647654094e-05\n",
      "[9360] Metric: \"tokens seen\"=983836\n",
      "[9360] Metric: \"epoch\"=0\n",
      "[9360] Metric: \"progress percent\"=9.567617295308189\n",
      "[9390] Metric: \"training loss\"=2.264756679534912\n",
      "[9390] Metric: \"learning rate\"=4.799141367678626e-05\n",
      "[9390] Metric: \"tokens seen\"=987052\n",
      "[9390] Metric: \"epoch\"=0\n",
      "[9390] Metric: \"progress percent\"=9.598282735357252\n",
      "[9400] Example (example): \"We feel our strength on time!\"\n",
      "[9420] Metric: \"training loss\"=2.2623867988586426\n",
      "[9420] Metric: \"learning rate\"=4.8144740877031584e-05\n",
      "[9420] Metric: \"tokens seen\"=990219\n",
      "[9420] Metric: \"epoch\"=0\n",
      "[9420] Metric: \"progress percent\"=9.628948175406316\n",
      "[9450] Metric: \"training loss\"=3.3773605823516846\n",
      "[9450] Metric: \"learning rate\"=4.8298068077276906e-05\n",
      "[9450] Metric: \"tokens seen\"=993659\n",
      "[9450] Metric: \"epoch\"=0\n",
      "[9450] Metric: \"progress percent\"=9.659613615455381\n",
      "[9480] Metric: \"training loss\"=1.5789490938186646\n",
      "[9480] Metric: \"learning rate\"=4.8451395277522235e-05\n",
      "[9480] Metric: \"tokens seen\"=997099\n",
      "[9480] Metric: \"epoch\"=0\n",
      "[9480] Metric: \"progress percent\"=9.690279055504448\n",
      "[9510] Metric: \"training loss\"=1.2340154647827148\n",
      "[9510] Metric: \"learning rate\"=4.860472247776756e-05\n",
      "[9510] Metric: \"tokens seen\"=1000172\n",
      "[9510] Metric: \"epoch\"=0\n",
      "[9510] Metric: \"progress percent\"=9.720944495553512\n",
      "[9540] Metric: \"training loss\"=3.5693209171295166\n",
      "[9540] Metric: \"learning rate\"=4.875804967801288e-05\n",
      "[9540] Metric: \"tokens seen\"=1003469\n",
      "[9540] Metric: \"epoch\"=0\n",
      "[9540] Metric: \"progress percent\"=9.751609935602575\n",
      "[9570] Metric: \"training loss\"=3.318802833557129\n",
      "[9570] Metric: \"learning rate\"=4.89113768782582e-05\n",
      "[9570] Metric: \"tokens seen\"=1006468\n",
      "[9570] Metric: \"epoch\"=0\n",
      "[9570] Metric: \"progress percent\"=9.78227537565164\n",
      "[9600] Metric: \"training loss\"=2.9424941539764404\n",
      "[9600] Metric: \"learning rate\"=4.9064704078503524e-05\n",
      "[9600] Metric: \"tokens seen\"=1009668\n",
      "[9600] Metric: \"epoch\"=0\n",
      "[9600] Metric: \"progress percent\"=9.812940815700705\n",
      "[9600] Example (example): \"1. What is the use of the adjective 'stirpative'?\n",
      "2. How many notes?\"\n",
      "[9600] Metric: \"validation loss\"=2.6160735733368816\n",
      "[9630] Metric: \"training loss\"=2.875922679901123\n",
      "[9630] Metric: \"learning rate\"=4.921803127874885e-05\n",
      "[9630] Metric: \"tokens seen\"=1012879\n",
      "[9630] Metric: \"epoch\"=0\n",
      "[9630] Metric: \"progress percent\"=9.843606255749771\n",
      "[9660] Metric: \"training loss\"=3.894174575805664\n",
      "[9660] Metric: \"learning rate\"=4.9371358478994175e-05\n",
      "[9660] Metric: \"tokens seen\"=1016401\n",
      "[9660] Metric: \"epoch\"=0\n",
      "[9660] Metric: \"progress percent\"=9.874271695798836\n",
      "[9690] Metric: \"training loss\"=3.0437591075897217\n",
      "[9690] Metric: \"learning rate\"=4.9524685679239504e-05\n",
      "[9690] Metric: \"tokens seen\"=1019555\n",
      "[9690] Metric: \"epoch\"=0\n",
      "[9690] Metric: \"progress percent\"=9.904937135847899\n",
      "[9720] Metric: \"training loss\"=2.680053472518921\n",
      "[9720] Metric: \"learning rate\"=4.9678012879484826e-05\n",
      "[9720] Metric: \"tokens seen\"=1022743\n",
      "[9720] Metric: \"epoch\"=0\n",
      "[9720] Metric: \"progress percent\"=9.935602575896963\n",
      "[9750] Metric: \"training loss\"=1.7143049240112305\n",
      "[9750] Metric: \"learning rate\"=4.983134007973015e-05\n",
      "[9750] Metric: \"tokens seen\"=1025909\n",
      "[9750] Metric: \"epoch\"=0\n",
      "[9750] Metric: \"progress percent\"=9.966268015946028\n",
      "[9780] Metric: \"training loss\"=3.915532350540161\n",
      "[9780] Metric: \"learning rate\"=4.998466727997547e-05\n",
      "[9780] Metric: \"tokens seen\"=1029192\n",
      "[9780] Metric: \"epoch\"=0\n",
      "[9780] Metric: \"progress percent\"=9.996933455995094\n",
      "[9800] Example (example): \"Fictuated\"\n",
      "[9810] Metric: \"training loss\"=2.5698623657226562\n",
      "[9810] Metric: \"learning rate\"=4.999998839866074e-05\n",
      "[9810] Metric: \"tokens seen\"=1032161\n",
      "[9810] Metric: \"epoch\"=0\n",
      "[9810] Metric: \"progress percent\"=10.027598896044159\n",
      "[9840] Metric: \"training loss\"=3.2938642501831055\n",
      "[9840] Metric: \"learning rate\"=4.999994829527959e-05\n",
      "[9840] Metric: \"tokens seen\"=1035408\n",
      "[9840] Metric: \"epoch\"=0\n",
      "[9840] Metric: \"progress percent\"=10.058264336093222\n",
      "[9870] Metric: \"training loss\"=1.8871732950210571\n",
      "[9870] Metric: \"learning rate\"=4.9999879546676065e-05\n",
      "[9870] Metric: \"tokens seen\"=1037856\n",
      "[9870] Metric: \"epoch\"=0\n",
      "[9870] Metric: \"progress percent\"=10.088929776142287\n",
      "[9900] Metric: \"training loss\"=1.972922444343567\n",
      "[9900] Metric: \"learning rate\"=4.999978215292895e-05\n",
      "[9900] Metric: \"tokens seen\"=1041307\n",
      "[9900] Metric: \"epoch\"=0\n",
      "[9900] Metric: \"progress percent\"=10.119595216191353\n",
      "[9930] Metric: \"training loss\"=1.606068730354309\n",
      "[9930] Metric: \"learning rate\"=4.999965611414985e-05\n",
      "[9930] Metric: \"tokens seen\"=1044259\n",
      "[9930] Metric: \"epoch\"=0\n",
      "[9930] Metric: \"progress percent\"=10.150260656240418\n",
      "[9960] Metric: \"training loss\"=2.3149988651275635\n",
      "[9960] Metric: \"learning rate\"=4.999950143048316e-05\n",
      "[9960] Metric: \"tokens seen\"=1047000\n",
      "[9960] Metric: \"epoch\"=0\n",
      "[9960] Metric: \"progress percent\"=10.180926096289483\n",
      "[9990] Metric: \"training loss\"=3.0395395755767822\n",
      "[9990] Metric: \"learning rate\"=4.999931810210613e-05\n",
      "[9990] Metric: \"tokens seen\"=1050372\n",
      "[9990] Metric: \"epoch\"=0\n",
      "[9990] Metric: \"progress percent\"=10.211591536338545\n",
      "[10000] Example (example): \"fjunctative (if_I had time).\"\n",
      "[10020] Metric: \"training loss\"=3.0781877040863037\n",
      "[10020] Metric: \"learning rate\"=4.999910612922882e-05\n",
      "[10020] Metric: \"tokens seen\"=1053551\n",
      "[10020] Metric: \"epoch\"=0\n",
      "[10020] Metric: \"progress percent\"=10.24225697638761\n",
      "[10050] Metric: \"training loss\"=2.875631809234619\n",
      "[10050] Metric: \"learning rate\"=4.999886551209411e-05\n",
      "[10050] Metric: \"tokens seen\"=1056510\n",
      "[10050] Metric: \"epoch\"=0\n",
      "[10050] Metric: \"progress percent\"=10.272922416436677\n",
      "[10080] Metric: \"training loss\"=3.3116824626922607\n",
      "[10080] Metric: \"learning rate\"=4.9998596250977694e-05\n",
      "[10080] Metric: \"tokens seen\"=1059484\n",
      "[10080] Metric: \"epoch\"=0\n",
      "[10080] Metric: \"progress percent\"=10.303587856485741\n",
      "[10110] Metric: \"training loss\"=2.3160555362701416\n",
      "[10110] Metric: \"learning rate\"=4.999829834618811e-05\n",
      "[10110] Metric: \"tokens seen\"=1063357\n",
      "[10110] Metric: \"epoch\"=0\n",
      "[10110] Metric: \"progress percent\"=10.334253296534806\n",
      "[10140] Metric: \"training loss\"=3.615142345428467\n",
      "[10140] Metric: \"learning rate\"=4.999797179806668e-05\n",
      "[10140] Metric: \"tokens seen\"=1066513\n",
      "[10140] Metric: \"epoch\"=0\n",
      "[10140] Metric: \"progress percent\"=10.364918736583869\n",
      "[10170] Metric: \"training loss\"=1.913848876953125\n",
      "[10170] Metric: \"learning rate\"=4.999761660698759e-05\n",
      "[10170] Metric: \"tokens seen\"=1069822\n",
      "[10170] Metric: \"epoch\"=0\n",
      "[10170] Metric: \"progress percent\"=10.395584176632934\n",
      "[10200] Metric: \"training loss\"=3.9322097301483154\n",
      "[10200] Metric: \"learning rate\"=4.99972327733578e-05\n",
      "[10200] Metric: \"tokens seen\"=1073190\n",
      "[10200] Metric: \"epoch\"=0\n",
      "[10200] Metric: \"progress percent\"=10.426249616682\n",
      "[10200] Example (example): \"The noun in the sentence is in the same character. \n",
      "He means \"not a man\". \n",
      "After talking about \"he\", he takes the \"last speaker\" as follows 1 paragraph.\n",
      "He expresses this statement, \"but his speech\". \n",
      " He speaks like a beast.\" \n",
      "His voice was heard by \"a beast\". \n",
      "His words \"he speaks as loud as a lion. \n",
      "As good his speech can appear as a dog. \n",
      "He can no doubt make mistakes over the way it passes from him. A dog also cannot use one word for what it describes. \n",
      "He would\"\n",
      "[10200] Metric: \"validation loss\"=2.596365126908994\n",
      "[10230] Metric: \"training loss\"=3.0783679485321045\n",
      "[10230] Metric: \"learning rate\"=4.999682029761714e-05\n",
      "[10230] Metric: \"tokens seen\"=1076197\n",
      "[10230] Metric: \"epoch\"=0\n",
      "[10230] Metric: \"progress percent\"=10.456915056731065\n",
      "[10260] Metric: \"training loss\"=3.51007080078125\n",
      "[10260] Metric: \"learning rate\"=4.999637918023819e-05\n",
      "[10260] Metric: \"tokens seen\"=1079476\n",
      "[10260] Metric: \"epoch\"=0\n",
      "[10260] Metric: \"progress percent\"=10.48758049678013\n",
      "[10290] Metric: \"training loss\"=2.25750732421875\n",
      "[10290] Metric: \"learning rate\"=4.999590942172642e-05\n",
      "[10290] Metric: \"tokens seen\"=1082791\n",
      "[10290] Metric: \"epoch\"=0\n",
      "[10290] Metric: \"progress percent\"=10.518245936829192\n",
      "[10320] Metric: \"training loss\"=2.0578649044036865\n",
      "[10320] Metric: \"learning rate\"=4.999541102262007e-05\n",
      "[10320] Metric: \"tokens seen\"=1085888\n",
      "[10320] Metric: \"epoch\"=0\n",
      "[10320] Metric: \"progress percent\"=10.548911376878259\n",
      "[10350] Metric: \"training loss\"=1.139654517173767\n",
      "[10350] Metric: \"learning rate\"=4.999488398349022e-05\n",
      "[10350] Metric: \"tokens seen\"=1089813\n",
      "[10350] Metric: \"epoch\"=0\n",
      "[10350] Metric: \"progress percent\"=10.579576816927323\n",
      "[10380] Metric: \"training loss\"=4.0662336349487305\n",
      "[10380] Metric: \"learning rate\"=4.999432830494074e-05\n",
      "[10380] Metric: \"tokens seen\"=1092822\n",
      "[10380] Metric: \"epoch\"=0\n",
      "[10380] Metric: \"progress percent\"=10.610242256976388\n",
      "[10400] Example (example): \"for  x y c x y c x 5\n",
      "     5 n. > |  __ + 1. == 5 + 5 m x i x + 1.| + 3\n",
      "     m, - n. AI+ [N + 2+ - a + 2+ - a + 6+ -- + 14 = c (x + 3+ n. AI+, = b), = c | - c and | - n c(2+ n\n",
      " - m: , - 1/3 c(+ 1:  is - + \" x i) (8):\n",
      "  2\"\n",
      "[10410] Metric: \"training loss\"=3.070537805557251\n",
      "[10410] Metric: \"learning rate\"=4.9993743987608344e-05\n",
      "[10410] Metric: \"tokens seen\"=1095728\n",
      "[10410] Metric: \"epoch\"=0\n",
      "[10410] Metric: \"progress percent\"=10.640907697025453\n",
      "[10440] Metric: \"training loss\"=2.1479969024658203\n",
      "[10440] Metric: \"learning rate\"=4.999313103216255e-05\n",
      "[10440] Metric: \"tokens seen\"=1099090\n",
      "[10440] Metric: \"epoch\"=0\n",
      "[10440] Metric: \"progress percent\"=10.671573137074516\n",
      "[10470] Metric: \"training loss\"=1.2708607912063599\n",
      "[10470] Metric: \"learning rate\"=4.999248943930569e-05\n",
      "[10470] Metric: \"tokens seen\"=1101424\n",
      "[10470] Metric: \"epoch\"=0\n",
      "[10470] Metric: \"progress percent\"=10.702238577123582\n",
      "[10500] Metric: \"training loss\"=1.9737471342086792\n",
      "[10500] Metric: \"learning rate\"=4.999181920977292e-05\n",
      "[10500] Metric: \"tokens seen\"=1104313\n",
      "[10500] Metric: \"epoch\"=0\n",
      "[10500] Metric: \"progress percent\"=10.732904017172647\n",
      "[10530] Metric: \"training loss\"=1.568290114402771\n",
      "[10530] Metric: \"learning rate\"=4.9991120344332166e-05\n",
      "[10530] Metric: \"tokens seen\"=1107494\n",
      "[10530] Metric: \"epoch\"=0\n",
      "[10530] Metric: \"progress percent\"=10.763569457221712\n",
      "[10560] Metric: \"training loss\"=3.321821928024292\n",
      "[10560] Metric: \"learning rate\"=4.9990392843784217e-05\n",
      "[10560] Metric: \"tokens seen\"=1110929\n",
      "[10560] Metric: \"epoch\"=0\n",
      "[10560] Metric: \"progress percent\"=10.794234897270776\n",
      "[10590] Metric: \"training loss\"=2.5433578491210938\n",
      "[10590] Metric: \"learning rate\"=4.998963670896265e-05\n",
      "[10590] Metric: \"tokens seen\"=1113852\n",
      "[10590] Metric: \"epoch\"=0\n",
      "[10590] Metric: \"progress percent\"=10.82490033731984\n",
      "[10600] Example (example): \"def.\"\n",
      "[10620] Metric: \"training loss\"=2.711129665374756\n",
      "[10620] Metric: \"learning rate\"=4.998885194073385e-05\n",
      "[10620] Metric: \"tokens seen\"=1117499\n",
      "[10620] Metric: \"epoch\"=0\n",
      "[10620] Metric: \"progress percent\"=10.855565777368906\n",
      "[10650] Metric: \"training loss\"=3.1784071922302246\n",
      "[10650] Metric: \"learning rate\"=4.9988038539997016e-05\n",
      "[10650] Metric: \"tokens seen\"=1121164\n",
      "[10650] Metric: \"epoch\"=0\n",
      "[10650] Metric: \"progress percent\"=10.88623121741797\n",
      "[10680] Metric: \"training loss\"=1.8984681367874146\n",
      "[10680] Metric: \"learning rate\"=4.998719650768414e-05\n",
      "[10680] Metric: \"tokens seen\"=1124440\n",
      "[10680] Metric: \"epoch\"=0\n",
      "[10680] Metric: \"progress percent\"=10.916896657467035\n",
      "[10710] Metric: \"training loss\"=1.9751192331314087\n",
      "[10710] Metric: \"learning rate\"=4.9986325844760054e-05\n",
      "[10710] Metric: \"tokens seen\"=1127644\n",
      "[10710] Metric: \"epoch\"=0\n",
      "[10710] Metric: \"progress percent\"=10.9475620975161\n",
      "[10740] Metric: \"training loss\"=3.5008509159088135\n",
      "[10740] Metric: \"learning rate\"=4.998542655222236e-05\n",
      "[10740] Metric: \"tokens seen\"=1131212\n",
      "[10740] Metric: \"epoch\"=0\n",
      "[10740] Metric: \"progress percent\"=10.978227537565164\n",
      "[10770] Metric: \"training loss\"=3.3474581241607666\n",
      "[10770] Metric: \"learning rate\"=4.998449863110147e-05\n",
      "[10770] Metric: \"tokens seen\"=1134452\n",
      "[10770] Metric: \"epoch\"=0\n",
      "[10770] Metric: \"progress percent\"=11.008892977614229\n",
      "[10800] Metric: \"training loss\"=1.2611802816390991\n",
      "[10800] Metric: \"learning rate\"=4.9983542082460624e-05\n",
      "[10800] Metric: \"tokens seen\"=1137483\n",
      "[10800] Metric: \"epoch\"=0\n",
      "[10800] Metric: \"progress percent\"=11.039558417663294\n",
      "[10800] Example (example): \"Peters, frogs, creatures.\"\n",
      "[10800] Metric: \"validation loss\"=2.5768757871553007\n",
      "[10830] Metric: \"training loss\"=2.52984619140625\n",
      "[10830] Metric: \"learning rate\"=4.9982556907395826e-05\n",
      "[10830] Metric: \"tokens seen\"=1140608\n",
      "[10830] Metric: \"epoch\"=0\n",
      "[10830] Metric: \"progress percent\"=11.070223857712358\n",
      "[10860] Metric: \"training loss\"=3.5976500511169434\n",
      "[10860] Metric: \"learning rate\"=4.998154310703592e-05\n",
      "[10860] Metric: \"tokens seen\"=1143727\n",
      "[10860] Metric: \"epoch\"=0\n",
      "[10860] Metric: \"progress percent\"=11.100889297761423\n",
      "[10890] Metric: \"training loss\"=2.101132392883301\n",
      "[10890] Metric: \"learning rate\"=4.998050068254252e-05\n",
      "[10890] Metric: \"tokens seen\"=1146979\n",
      "[10890] Metric: \"epoch\"=0\n",
      "[10890] Metric: \"progress percent\"=11.131554737810488\n",
      "[10920] Metric: \"training loss\"=3.239021062850952\n",
      "[10920] Metric: \"learning rate\"=4.9979429635110044e-05\n",
      "[10920] Metric: \"tokens seen\"=1149997\n",
      "[10920] Metric: \"epoch\"=0\n",
      "[10920] Metric: \"progress percent\"=11.162220177859552\n",
      "[10950] Metric: \"training loss\"=1.8979449272155762\n",
      "[10950] Metric: \"learning rate\"=4.9978329965965726e-05\n",
      "[10950] Metric: \"tokens seen\"=1152949\n",
      "[10950] Metric: \"epoch\"=0\n",
      "[10950] Metric: \"progress percent\"=11.192885617908617\n",
      "[10980] Metric: \"training loss\"=1.5536404848098755\n",
      "[10980] Metric: \"learning rate\"=4.997720167636956e-05\n",
      "[10980] Metric: \"tokens seen\"=1155690\n",
      "[10980] Metric: \"epoch\"=0\n",
      "[10980] Metric: \"progress percent\"=11.223551057957682\n",
      "[11000] Example (example): \"This word will include the power, security, or comfort of the article for each branch with instructions.\"\n",
      "[11010] Metric: \"training loss\"=1.3460924625396729\n",
      "[11010] Metric: \"learning rate\"=4.997604476761437e-05\n",
      "[11010] Metric: \"tokens seen\"=1158464\n",
      "[11010] Metric: \"epoch\"=0\n",
      "[11010] Metric: \"progress percent\"=11.254216498006747\n",
      "[11040] Metric: \"training loss\"=3.166044235229492\n",
      "[11040] Metric: \"learning rate\"=4.997485924102574e-05\n",
      "[11040] Metric: \"tokens seen\"=1162306\n",
      "[11040] Metric: \"epoch\"=0\n",
      "[11040] Metric: \"progress percent\"=11.284881938055811\n",
      "[11070] Metric: \"training loss\"=1.601823329925537\n",
      "[11070] Metric: \"learning rate\"=4.9973645097962066e-05\n",
      "[11070] Metric: \"tokens seen\"=1165474\n",
      "[11070] Metric: \"epoch\"=0\n",
      "[11070] Metric: \"progress percent\"=11.315547378104876\n",
      "[11100] Metric: \"training loss\"=2.325770139694214\n",
      "[11100] Metric: \"learning rate\"=4.9972402339814536e-05\n",
      "[11100] Metric: \"tokens seen\"=1168361\n",
      "[11100] Metric: \"epoch\"=0\n",
      "[11100] Metric: \"progress percent\"=11.34621281815394\n",
      "[11130] Metric: \"training loss\"=3.602442741394043\n",
      "[11130] Metric: \"learning rate\"=4.9971130968007096e-05\n",
      "[11130] Metric: \"tokens seen\"=1171561\n",
      "[11130] Metric: \"epoch\"=0\n",
      "[11130] Metric: \"progress percent\"=11.376878258203005\n",
      "[11160] Metric: \"training loss\"=3.320427417755127\n",
      "[11160] Metric: \"learning rate\"=4.996983098399652e-05\n",
      "[11160] Metric: \"tokens seen\"=1174261\n",
      "[11160] Metric: \"epoch\"=0\n",
      "[11160] Metric: \"progress percent\"=11.40754369825207\n",
      "[11190] Metric: \"training loss\"=2.5224685668945312\n",
      "[11190] Metric: \"learning rate\"=4.9968502389272334e-05\n",
      "[11190] Metric: \"tokens seen\"=1177340\n",
      "[11190] Metric: \"epoch\"=0\n",
      "[11190] Metric: \"progress percent\"=11.438209138301135\n",
      "[11200] Example (example): \"fagining is like looking the street to go, but it seems to be too busy because it provides people better luck so much. With their eyes set they must stay looking after the country’s health and get enough luck to get ready money to their journey afield. They need better manage their job as best one day, then find some money that would soon stay up. Furthermore, since these people would travel across it in a better shape.\"\n",
      "[11220] Metric: \"training loss\"=2.1229255199432373\n",
      "[11220] Metric: \"learning rate\"=4.996714518535685e-05\n",
      "[11220] Metric: \"tokens seen\"=1180210\n",
      "[11220] Metric: \"epoch\"=0\n",
      "[11220] Metric: \"progress percent\"=11.4688745783502\n",
      "[11250] Metric: \"training loss\"=2.487509250640869\n",
      "[11250] Metric: \"learning rate\"=4.996575937380518e-05\n",
      "[11250] Metric: \"tokens seen\"=1183305\n",
      "[11250] Metric: \"epoch\"=0\n",
      "[11250] Metric: \"progress percent\"=11.499540018399264\n",
      "[11280] Metric: \"training loss\"=2.483259439468384\n",
      "[11280] Metric: \"learning rate\"=4.9964344956205186e-05\n",
      "[11280] Metric: \"tokens seen\"=1186523\n",
      "[11280] Metric: \"epoch\"=0\n",
      "[11280] Metric: \"progress percent\"=11.530205458448329\n",
      "[11310] Metric: \"training loss\"=2.526358127593994\n",
      "[11310] Metric: \"learning rate\"=4.996290193417755e-05\n",
      "[11310] Metric: \"tokens seen\"=1189723\n",
      "[11310] Metric: \"epoch\"=0\n",
      "[11310] Metric: \"progress percent\"=11.560870898497393\n",
      "[11340] Metric: \"training loss\"=3.834670305252075\n",
      "[11340] Metric: \"learning rate\"=4.996143030937568e-05\n",
      "[11340] Metric: \"tokens seen\"=1192496\n",
      "[11340] Metric: \"epoch\"=0\n",
      "[11340] Metric: \"progress percent\"=11.591536338546458\n",
      "[11370] Metric: \"training loss\"=1.9124104976654053\n",
      "[11370] Metric: \"learning rate\"=4.995993008348579e-05\n",
      "[11370] Metric: \"tokens seen\"=1195053\n",
      "[11370] Metric: \"epoch\"=0\n",
      "[11370] Metric: \"progress percent\"=11.622201778595523\n",
      "[11400] Metric: \"training loss\"=1.6596112251281738\n",
      "[11400] Metric: \"learning rate\"=4.995840125822685e-05\n",
      "[11400] Metric: \"tokens seen\"=1198223\n",
      "[11400] Metric: \"epoch\"=0\n",
      "[11400] Metric: \"progress percent\"=11.652867218644587\n",
      "[11400] Example (example): \"possible - \n",
      "possible \n",
      "<pobstitute\"\n",
      "[11400] Metric: \"validation loss\"=2.561236972317976\n",
      "[11430] Metric: \"training loss\"=2.524153232574463\n",
      "[11430] Metric: \"learning rate\"=4.995684383535061e-05\n",
      "[11430] Metric: \"tokens seen\"=1201553\n",
      "[11430] Metric: \"epoch\"=0\n",
      "[11430] Metric: \"progress percent\"=11.683532658693652\n",
      "[11460] Metric: \"training loss\"=3.0565097332000732\n",
      "[11460] Metric: \"learning rate\"=4.995525781664159e-05\n",
      "[11460] Metric: \"tokens seen\"=1204631\n",
      "[11460] Metric: \"epoch\"=0\n",
      "[11460] Metric: \"progress percent\"=11.714198098742717\n",
      "[11490] Metric: \"training loss\"=2.1567718982696533\n",
      "[11490] Metric: \"learning rate\"=4.995364320391704e-05\n",
      "[11490] Metric: \"tokens seen\"=1207850\n",
      "[11490] Metric: \"epoch\"=0\n",
      "[11490] Metric: \"progress percent\"=11.744863538791781\n",
      "[11520] Metric: \"training loss\"=2.6562721729278564\n",
      "[11520] Metric: \"learning rate\"=4.9951999999027036e-05\n",
      "[11520] Metric: \"tokens seen\"=1211161\n",
      "[11520] Metric: \"epoch\"=0\n",
      "[11520] Metric: \"progress percent\"=11.775528978840846\n",
      "[11550] Metric: \"training loss\"=2.758148193359375\n",
      "[11550] Metric: \"learning rate\"=4.995032820385437e-05\n",
      "[11550] Metric: \"tokens seen\"=1213991\n",
      "[11550] Metric: \"epoch\"=0\n",
      "[11550] Metric: \"progress percent\"=11.80619441888991\n",
      "[11580] Metric: \"training loss\"=2.47507643699646\n",
      "[11580] Metric: \"learning rate\"=4.9948627820314586e-05\n",
      "[11580] Metric: \"tokens seen\"=1216948\n",
      "[11580] Metric: \"epoch\"=0\n",
      "[11580] Metric: \"progress percent\"=11.836859858938977\n",
      "[11600] Example (example): \"I love music at this moment.\"\n",
      "[11610] Metric: \"training loss\"=1.0057923793792725\n",
      "[11610] Metric: \"learning rate\"=4.994689885035602e-05\n",
      "[11610] Metric: \"tokens seen\"=1220032\n",
      "[11610] Metric: \"epoch\"=0\n",
      "[11610] Metric: \"progress percent\"=11.86752529898804\n",
      "[11640] Metric: \"training loss\"=4.321946620941162\n",
      "[11640] Metric: \"learning rate\"=4.9945141295959745e-05\n",
      "[11640] Metric: \"tokens seen\"=1223020\n",
      "[11640] Metric: \"epoch\"=0\n",
      "[11640] Metric: \"progress percent\"=11.898190739037105\n",
      "[11670] Metric: \"training loss\"=2.9932379722595215\n",
      "[11670] Metric: \"learning rate\"=4.9943355159139585e-05\n",
      "[11670] Metric: \"tokens seen\"=1225885\n",
      "[11670] Metric: \"epoch\"=0\n",
      "[11670] Metric: \"progress percent\"=11.92885617908617\n",
      "[11700] Metric: \"training loss\"=1.620667815208435\n",
      "[11700] Metric: \"learning rate\"=4.99415404419421e-05\n",
      "[11700] Metric: \"tokens seen\"=1228384\n",
      "[11700] Metric: \"epoch\"=0\n",
      "[11700] Metric: \"progress percent\"=11.959521619135234\n",
      "[11730] Metric: \"training loss\"=1.87093186378479\n",
      "[11730] Metric: \"learning rate\"=4.993969714644664e-05\n",
      "[11730] Metric: \"tokens seen\"=1231205\n",
      "[11730] Metric: \"epoch\"=0\n",
      "[11730] Metric: \"progress percent\"=11.9901870591843\n",
      "[11760] Metric: \"training loss\"=1.4424244165420532\n",
      "[11760] Metric: \"learning rate\"=4.993782527476526e-05\n",
      "[11760] Metric: \"tokens seen\"=1234505\n",
      "[11760] Metric: \"epoch\"=0\n",
      "[11760] Metric: \"progress percent\"=12.020852499233364\n",
      "[11790] Metric: \"training loss\"=1.9055272340774536\n",
      "[11790] Metric: \"learning rate\"=4.993592482904277e-05\n",
      "[11790] Metric: \"tokens seen\"=1237251\n",
      "[11790] Metric: \"epoch\"=0\n",
      "[11790] Metric: \"progress percent\"=12.051517939282428\n",
      "[11800] Example (example): \"defascivity: adoration: Adverb. \n",
      "\n",
      "### Response:\n",
      "Glimbs have a different expression than {^2} (fendable} noun.\"\n",
      "[11820] Metric: \"training loss\"=1.8744755983352661\n",
      "[11820] Metric: \"learning rate\"=4.993399581145672e-05\n",
      "[11820] Metric: \"tokens seen\"=1239983\n",
      "[11820] Metric: \"epoch\"=0\n",
      "[11820] Metric: \"progress percent\"=12.082183379331493\n",
      "[11850] Metric: \"training loss\"=1.9621061086654663\n",
      "[11850] Metric: \"learning rate\"=4.993203822421741e-05\n",
      "[11850] Metric: \"tokens seen\"=1242813\n",
      "[11850] Metric: \"epoch\"=0\n",
      "[11850] Metric: \"progress percent\"=12.112848819380558\n"
     ]
    }
   ],
   "source": [
    "def train_model_on_big_example_set(model: gpt.GPTModel):\n",
    "    example_prompt = format_input({\n",
    "        'instruction': \"Convert this sentence to passive voice.\",\n",
    "        'input': 'The chef cooked the meal.',\n",
    "        'output': ''}, include_response=True)\n",
    "\n",
    "    training_config = training.new_training_config(\n",
    "         gradient_clipping = False,\n",
    "         epochs = 2,\n",
    "         peak_lr = 5e-5,\n",
    "         initial_lr = 4e-6,\n",
    "         eval_freq = 200,\n",
    "     )\n",
    "\n",
    "    optimizer = training.default_optimizer(model, training_config)\n",
    "\n",
    "    training.train(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        training_loader=alpaca_train,\n",
    "        validation_loader=alpaca_val,\n",
    "        cfg=training_config,\n",
    "        metrics=training.StdoutMetrics(print_interval=30),\n",
    "        example_generator=LlamaExampleGenerator(instruction=\"Use this word in a sentence\", input=\"fascinating\"),\n",
    "    )\n",
    "\n",
    "# gpt355m = openai.load_openai_model(openai.GPT_CONFIG_355M, \"355M\")\n",
    "# train_model_on_big_example_set(gpt355m)\n",
    "# training.save(model=model, optimizer=None, name=\"fine-tuned-355m-alpaca\")\n",
    "\n",
    "# train_model_on_big_example_set(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01320a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = gpt.GPTModel(cfg=openai.GPT_CONFIG_355M, training_cfg=gpt.DEFAULT_TRAINING_CONFIG)\n",
    "# llm.load(\"fine-tuned-355m-alpaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct(llm, \"Are you conscious?\", temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c67031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_example_responses(model: gpt.GPTModel, examples: list[InstructionExample], temperature:float=0.8, file_path:str=\"model_output.json\"):\n",
    "    results = []\n",
    "    for ex in examples:\n",
    "        model_response = instruct_str(model, ex['instruction'], ex['input'], temperature=temperature)\n",
    "        results.append({\n",
    "            'instruction': ex['instruction'],\n",
    "            'input': ex['input'],\n",
    "            'output': ex['output'],\n",
    "            'model_output': model_response,\n",
    "        })\n",
    "    json_body = json.dumps(results, indent=4)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(json_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_example_responses(model=model, examples=test_data, file_path=\"small_training_output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f5022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
