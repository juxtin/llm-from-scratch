{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb011898",
   "metadata": {},
   "source": [
    "# Training on Project Gutenberg\n",
    "\n",
    "The following few sections include the code necessary to:\n",
    "1. Preprocess the [deepmind/pg19](https://huggingface.co/datasets/deepmind/pg19) dataset and wrap it in a Dataset class that we can use for training.\n",
    "2. Sample some batches from the dataset to see what typical text looks like.\n",
    "3. Train a GPTModel with a context size of 512 on this corpus.\n",
    "\n",
    "If you want to do this, better get a big cup of coffee and about 60 gigs of\n",
    "space ready. Downloading the data from HuggingFace takes a while, then you have\n",
    "to expand it and then the LazyTokenDatasetPG19 class will create a cache containing\n",
    "tokenized versions of every text.\n",
    "\n",
    "After that, training takes about 6-8 hours to reach a plateau on my machine with an NVidia 3080."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad38c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n",
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 02:46:32.322272: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-06 02:46:32.333443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751769992.347404    9162 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751769992.351286    9162 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751769992.361873    9162 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751769992.361890    9162 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751769992.361892    9162 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751769992.361892    9162 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-06 02:46:32.365953: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import gpt # type: ignore\n",
    "from gpt import GPTModel # type: ignore\n",
    "from training import TrainingConfig, new_training_config, train # type: ignore\n",
    "import training # type: ignore\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "import textwrap\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa037778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyTokenDatasetPG19(Dataset):\n",
    "    \"\"\"Preprocesses the dataset (assumed to be deepmind/pg19!) by creating a\n",
    "    directory './tokens' containing pre-tokenized versions of all books in the\n",
    "    dataset. This takes a while the first time you run it (maybe 20 minutes),\n",
    "    but after that it's just a few seconds.\n",
    "    \n",
    "    The initialized object is suitable for passing to Dataloader.\"\"\"\n",
    "    GUTENBERG_END_RE = re.compile(r\"(?i)end of (the )?project gutenberg.*\", re.DOTALL)\n",
    "    TOO_MANY_NEWLINES_RE = re.compile(r\"\\n{3,}\")\n",
    "    LEADING_NEWLINES_RE = re.compile(r\"^\\n+\")\n",
    "    \n",
    "    def __init__(self, context_len:int=256):\n",
    "        super().__init__()\n",
    "        self.context_len = context_len\n",
    "        self.preprocess()\n",
    "        self.file_paths = glob.glob(\"tokens/*.pt\")\n",
    "        self.samples: list[tuple[int, int]] = []\n",
    "        print(\"Loading data from tokens directory\")\n",
    "        for i, path in enumerate(self.file_paths):\n",
    "            length = torch.load(path, map_location=\"cpu\").shape[0]\n",
    "            for j in range(0, length - context_len, context_len):\n",
    "                self.samples.append((i, j))\n",
    "            if i % 5_000 == 0:\n",
    "                print(f\"Loaded up to book {i}...\")\n",
    "        print(\"Loading complete\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        book_idx, start = self.samples[idx]\n",
    "        tokens = torch.load(self.file_paths[book_idx], map_location=\"cpu\")\n",
    "        input_ids = tokens[start : start + self.context_len]\n",
    "        target_ids = tokens[start + 1 : start + self.context_len + 1]\n",
    "        return input_ids, target_ids\n",
    "\n",
    "    def preprocess(self):\n",
    "        os.makedirs(\"tokens\", exist_ok=True)\n",
    "        existing_filepaths = glob.glob(\"tokens/book_*.pt\")\n",
    "        if len(existing_filepaths) >= 28_000: # the approx size of the expanded tokens dir\n",
    "            print(\"Preprocessing not needed.\")\n",
    "            return\n",
    "        ds = load_dataset(\"deepmind/pg19\", split=\"train\")\n",
    "        print(\"Preprocessing data to tokens directory.\")\n",
    "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        for i, book in enumerate(ds):\n",
    "            path = Path(f\"tokens/book_{i}.pt\")\n",
    "            if path.exists():\n",
    "                continue\n",
    "            text = self.clean_text(book['text'])\n",
    "            if len(text) < self.context_len + 1:\n",
    "                continue\n",
    "            tokens = tokenizer.encode(text)\n",
    "            torch.save(torch.tensor(tokens, dtype=torch.long), path)\n",
    "            if i % 1_000 == 0:\n",
    "                print(f\"Completed preprocessing book {i}\")\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        # Remove Gutenberg end matter\n",
    "        text = self.GUTENBERG_END_RE.split(text)[0]\n",
    "        # Remove leading newlines/whitespace\n",
    "        text = self.LEADING_NEWLINES_RE.sub(\"\", text)\n",
    "        # Collapse 3+ newlines into exactly 2 (paragraph break)\n",
    "        text = self.TOO_MANY_NEWLINES_RE.sub(\"\\n\\n\", text)\n",
    "        # Eliminate chapter:verse markings\n",
    "        text = re.sub(r'\\b\\d+:\\d+\\b', '', text)\n",
    "        # Unwrap lines in each paragraph, but preserve paragraphs\n",
    "        paragraphs = text.split('\\n\\n')\n",
    "        unwrapped_paragraphs = [re.sub(r\"\\n\", \" \", p) for p in paragraphs]\n",
    "        text = '\\n\\n'.join(unwrapped_paragraphs)\n",
    "        # don't allow multiple spaces in a row\n",
    "        text = re.sub(r\"[^\\S\\n]+\", \" \", text)\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8493b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_loader(dataloader, n):\n",
    "    \"\"\"Given a DataLoader and a number of samples, prints batches from the DataLoader.\"\"\"\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    i = n\n",
    "    for input_batch, target_batch in dataloader:\n",
    "        if i == 0:\n",
    "            break\n",
    "        i -= 1\n",
    "        text = tokenizer.decode(input_batch.tolist()[:64])\n",
    "        print(text)\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "# Uncomment below to see what's in the sanitized pg19 dataset.\n",
    "# sample_loader(DataLoader(ltds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5112be82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing not needed.\n",
      "Loading data from tokens directory\n",
      "Loaded up to book 0...\n",
      "Loaded up to book 5000...\n",
      "Loaded up to book 10000...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m GPT_CONFIG_MEDIUM: gpt\u001b[38;5;241m.\u001b[39mGPTConfigDict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgpt\u001b[38;5;241m.\u001b[39mGPT_CONFIG_124M, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m} \u001b[38;5;66;03m# 1024 is just too big to train locally\u001b[39;00m\n\u001b[1;32m      2\u001b[0m GPT_CONFIG_LARGE: gpt\u001b[38;5;241m.\u001b[39mGPTConfigDict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopenai\u001b[38;5;241m.\u001b[39mGPT_CONFIG_774M, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m}\n\u001b[0;32m----> 3\u001b[0m ltds \u001b[38;5;241m=\u001b[39m \u001b[43mLazyTokenDatasetPG19\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m training_cfg: TrainingConfig \u001b[38;5;241m=\u001b[39m new_training_config(\n\u001b[1;32m      5\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m     eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# max_validation_batches=4,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# model = GPTModel(GPT_CONFIG_MEDIUM)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m, in \u001b[0;36mLazyTokenDatasetPG19.__init__\u001b[0;34m(self, context_len)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data from tokens directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_paths):\n\u001b[0;32m---> 20\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, length \u001b[38;5;241m-\u001b[39m context_len, context_len):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\u001b[38;5;241m.\u001b[39mappend((i, j))\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/torch/serialization.py:1516\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1516\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/torch/serialization.py:2114\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   2113\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 2114\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2117\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/torch/_weights_only_unpickler.py:491\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m EMPTY_TUPLE[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(())\n\u001b[0;32m--> 491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m EMPTY_LIST[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend([])\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m EMPTY_DICT[\u001b[38;5;241m0\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GPT_CONFIG_MEDIUM: gpt.GPTConfigDict = {**gpt.GPT_CONFIG_124M, \"context_length\": 512} # 1024 is just too big to train locally\n",
    "GPT_CONFIG_LARGE: gpt.GPTConfigDict = {**openai.GPT_CONFIG_774M, \"context_length\": 512}\n",
    "ltds = LazyTokenDatasetPG19(context_len=512)\n",
    "training_cfg: TrainingConfig = new_training_config(\n",
    "    epochs=1,\n",
    "    eval_freq=500,\n",
    "    peak_lr=1.5e-3, # 1.5e-3 for 774M, 1e-3 for 355M\n",
    "    max_length=512,\n",
    "    # max_validation_batches=4,\n",
    ")\n",
    "# model = GPTModel(GPT_CONFIG_MEDIUM)\n",
    "model = GPTModel(GPT_CONFIG_LARGE)\n",
    "model.to(gpt.get_device())\n",
    "optimizer = training.default_optimizer(model, training_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae7288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run flawless-bird-794 at: http://localhost:5000/#/experiments/0/runs/c855002bea424db79c8dfb6a4570046e\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m\n\u001b[1;32m     22\u001b[0m     train(\n\u001b[1;32m     23\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     24\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         metrics\u001b[38;5;241m=\u001b[39mtraining\u001b[38;5;241m.\u001b[39mMLflowMetrics(),\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Uncomment below to actually train the model. You won't get good results until you do.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# training.load(model, optimizer, \"pg19_medium\")\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtrain_pg19\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_training_run\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mtrain_pg19\u001b[0;34m(name, dataset, force_refresh)\u001b[0m\n\u001b[1;32m      9\u001b[0m training_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     10\u001b[0m     dataset,\n\u001b[1;32m     11\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     13\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m validation_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     16\u001b[0m     walden_ds, \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     19\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMLflowMetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:55\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, training_loader, validation_loader, cfg, lr_schedule_fn, metrics, example_generator)\u001b[0m\n",
      "File \u001b[0;32m<string>:76\u001b[0m, in \u001b[0;36mlog_metric\u001b[0;34m(self, name, val, step)\u001b[0m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/tracking/fluent.py:958\u001b[0m, in \u001b[0;36mlog_metric\u001b[0;34m(key, value, step, synchronous, timestamp, run_id, model_id, dataset)\u001b[0m\n\u001b[1;32m    956\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    957\u001b[0m model_id \u001b[38;5;241m=\u001b[39m model_id \u001b[38;5;129;01mor\u001b[39;00m get_active_model_id()\n\u001b[0;32m--> 958\u001b[0m \u001b[43m_log_inputs_for_metrics_if_necessary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMetric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdigest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m timestamp \u001b[38;5;129;01mor\u001b[39;00m get_current_time_millis()\n\u001b[1;32m    974\u001b[0m step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/tracking/fluent.py:998\u001b[0m, in \u001b[0;36m_log_inputs_for_metrics_if_necessary\u001b[0;34m(run_id, metrics, datasets)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_log_inputs_for_metrics_if_necessary\u001b[39m(\n\u001b[1;32m    995\u001b[0m     run_id, metrics: \u001b[38;5;28mlist\u001b[39m[Metric], datasets: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    996\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m     client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m--> 998\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m datasets \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/tracking/client.py:267\u001b[0m, in \u001b[0;36mMlflowClient.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Run:\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:98\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mcontains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mas well as a collection of run parameters, tags, and metrics --\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m _validate_run_id(run_id)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:229\u001b[0m, in \u001b[0;36mRestStore.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mFetch the run from backend store\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    A single Run object if it exists, otherwise raises an Exception\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(GetRun(run_uuid\u001b[38;5;241m=\u001b[39mrun_id, run_id\u001b[38;5;241m=\u001b[39mrun_id))\n\u001b[0;32m--> 229\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGetRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Run\u001b[38;5;241m.\u001b[39mfrom_proto(response_proto\u001b[38;5;241m.\u001b[39mrun)\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:135\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[0m\n\u001b[1;32m    133\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m    134\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:585\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    584\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[0;32m--> 585\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mhttp_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:229\u001b[0m, in \u001b[0;36mhttp_request\u001b[0;34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fetch_auth(host_creds\u001b[38;5;241m.\u001b[39mauth)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_http_response_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackoff_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackoff_jitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost_creds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m to:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with timeout exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m To increase the timeout, set the environment variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMLFLOW_HTTP_REQUEST_TIMEOUT\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m to a larger value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mto\u001b[39;00m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/mlflow/utils/request_utils.py:237\u001b[0m, in \u001b[0;36m_get_http_response_with_retries\u001b[0;34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m env_value \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLFLOW_ALLOW_HTTP_REDIRECTS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    235\u001b[0m allow_redirects \u001b[38;5;241m=\u001b[39m env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/llm-from-scratch/.venv/lib/python3.10/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_pg19(name: str, dataset: Dataset = ltds, force_refresh:bool=False):\n",
    "    with open('walden.txt') as f:\n",
    "        walden_txt = f.read()\n",
    "    walden_ds = training.GPTDatasetV1(walden_txt, tokenizer=tiktoken.get_encoding(\"gpt2\"), max_length=512, stride=256)\n",
    "    if force_refresh:\n",
    "        training.load(model, optimizer, name)\n",
    "    \n",
    "    batch_size=12\n",
    "    training_loader = DataLoader(\n",
    "        dataset,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        walden_ds, # type: ignore\n",
    "        shuffle=True,\n",
    "        batch_size=4,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    train(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        training_loader=training_loader,\n",
    "        validation_loader=validation_loader,\n",
    "        cfg=training_cfg,\n",
    "        metrics=training.MLflowMetrics(),\n",
    "        example_generator=training.SimpleCompletion(prompt=\"John held up his hands and\", max_new_tokens=24, temperature=0.4)\n",
    "    )\n",
    "\n",
    "# Uncomment below to actually train the model. You won't get good results until you do.\n",
    "# training.load(model, optimizer, \"pg19_medium\")\n",
    "training.load(model, optimizer, name=\"pg19_755M_partial\", base_path=\"/workspace\")\n",
    "training_cfg['gradient_clipping'] = True\n",
    "train_pg19(\"new_training_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(model: GPTModel, txt:str, max_tokens=128, temperature=0.8):\n",
    "    result = model.prompt(txt, max_tokens=max_tokens, temperature=temperature)\n",
    "    print(textwrap.fill(result, width=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model is trained, you should see some... interesting results from this.\n",
    "# Otherwise it'll just be gibberish.\n",
    "# prompt(model, \"Ere thrice the sun done salutation to the dawn,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ef755",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.save(model, optimizer, name=\"pg19_755M_partial\", base_path=\"/workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0d674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
